---
title: "Report"
author: "Brendi Ang"
date: "01/11/2021"
output: 
  bookdown::html_document2:
    theme: flatly
    citation_package: biblatex
    toc: true
    number_sections: false
    toc_float:
      collapsed: yes 
bibliography: references.bib
biblio-style: apa
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
library(broom)
library(broom.mixed)
library(colorspace)
library(kableExtra)
library(lme4)
library(naniar)
library(patchwork)

ggplot2::theme_set(theme_bw())

select <- dplyr::select
```

```{r}
# Read-in data
mathsci_all <- read_csv(here::here("data/mathsci_all.csv"),
                        # Changing variable type avoids errors
                        col_types = cols(doe_centre_code = col_factor()))

# Convert data types
mathsci_all <- mathsci_all %>% 
  mutate(across(.cols = c(qcaa_subject_id, 
                          subject_type,
                          qcaa_school_id,
                          sector,
                          school_postcode
                          ),
                ~ as.factor(.x))) 
```

# Objectives

This report critically analyses the trends in enrolments for senior secondary (Year 11 and Year 12) mathematics and science subjects in Queensland. Initially, the dataset will be described, from how the dataset is obtained to how the raw data was restructured, cleaned and augmented to facilitate the analysis. This includes imputing missing values, using regular expressions to manipulate character strings and relational joins to combine datasets with matching observations. Next, exploratory data analysis will be conducted using modern data exploration tools to uncover the underlying structures and interesting features of enrolment in all subjects; This will consist of graphical displays such as time plots to better understand the dataset. 

The aforementioned measures taken above gives readers an intuition of the dataset, the report will subsequently focus on building a statistical model to predict enrolments for senior secondary mathematics and science subjects. As the dataset is longitudinal, that is, involving a collection of data (enrolments) from the same school across multiple time points, a multilevel model is deemed appropriate for this analysis. This section of the report will further elaborate the methodology in producing the most appropriate model and the predictions from the 'best' model.

The following research questions guided the report:

(1) What are the underlying trends in senior secondary mathematics and science subjects? 
(2) Are there differences in enrolments in the new QCE system (after 2020) as compared to the old QCE system (before 2020)?


# Data and Motivation

## Extracting the dataset

```{r}
data_desc <- tibble(
  Variable =
    c(
      # Enrolment details
      "completion_year",
      "year_11_enrolments",
      "year_12_enrolments",
      # Subject details
      "qcaa_subject_id",
      "subject_name",
      "subject",
      "subject_type",
      # School details
      "qcaa_school_id",
      "school_name",
      "doe_centre_code",
      "qcaa_district",
      "school_postcode",
      "sector"
    ),
  Description =
    c(
      # Enrolment details
      "Graduation cohort's year of completion",
      "Number of Year 11 students enrolled in the subject",
      "Number of Year 12 students enrolled in the subject",
      # Subject details
      "QCAA subject ID",
      "Subject name",
      "Mathematics or Science subject",
      "Type of subject (General, applied or short courses)",
      # School detail
      "QCAA school ID",
      "School Name",
      "Department of Education Centre Code",
      "School district",
      "School postcode",
      "School sector (Government, Independent, Catholic)"
    ))

data_desc %>% 
  kable(caption = "Description of the dataset used for the analysis") %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = c("hovered", "striped")) %>% 
  pack_rows(index = c("Enrolment information" = 3,
                    "Subject information" = 4,
                    "School information" = 6)) 
```


The dataset used for this analysis encompasses enrolment information for all participating schools in the QCE system, and can be extracted in the Queensland Curriculum and Assessment Authority (QCAA) website, where the enrolments data for the old QCE system (enrolments spanning from 1992 to 2019) can be found under the ["Statistics before 2020" toggle](https://www.qcaa.qld.edu.au/news-data/statistics/statistics-before-2020) (@school-participation) while the enrolments data for the new QCE system can be found under the ["Statistics from 2020" toggle](https://www.qcaa.qld.edu.au/news-data/statistics/statistics-from-2020). 

Each row (observation) corresponds to a school's enrolment information for a subject in a given year, in addition to the school and subject details. The dataset can be broken down into the three main components, as seen above (Table \@ref(tab:data-description)). The data above has been cleaned and is ready for the format that allows for analysis, the further sections will describe the data wrangling process in details.

## The new QCE system

Senior schooling is a pivotal moment for Queensland students as most students transition into tertiary education. The new QCE system was introduced from Year 11 students in 2019, where Overall Position (OP) scores will be replaced by the new Australian Tertiary Admission Rank (ATAR) system in assisting universities in selecting applications in their courses. For this reason, the Queensland Core Skills (QCS) test for year 12 students, which has been in place since 1992 is abolished (after Year 12 in 2019) for the new ATAR system. The ATAR is a inter subject percentile-rank (as opposed to a mark), where students are ranked relative to their age group; To be specific, ATAR is expressed on a 2,000 point scale from 99.95 down to 0.00 in steps of 0.05. 

Queensland ATARs are based on a student's:

  - Best five general subject results, or
  - Best results in four General subjects, plus one Applied subject, or
  - Best results in four General subjects, plus one VET qualification at Certificate III or above

In the ATAR calculation, only *one* applied subject can be included in the ATAR calculation. For instance, if a student enrols in Essential Mathematics (applied subject) and Science in Practice	(Applied subject), only the higher of both 

## A new suite of senior mathematics and science subjects

In light of the new system, a new suite of senior subjects are reviewed and redeveloped, along with new ones introduced. The new senior syllabuses include **general (extension) subjects** for students who wish to pursue tertiary pathways, vocational education and training, and work. These subjects will have four summative assessments --- three internal and one external examination at the end of Year 12, which are set and marked by independent teacher assessors accredited by the Queensland Curriculum and Assessment Authority. On the other hand, **applied (essential) subjects** are mainly for students interested in pathways beyond school that primarily lead to vocational education and training or directly to work. These subjects tend to be more 'real world' focus and do not have external examinations but have a total of four summative internal assessments.

Notably, this report will not cover **short courses**, which are suited for students who wants to establish a basis for further education or work, typically leading to further vocational education and training.

### Mathematics

```{r qce-math}
# --- Mathematics
mathsci_all %>% 
  filter(subject == "Mathematics") %>% 
  # All unique mathematics subjects
  distinct(subject_name, subject_type) %>% 
  # Include Mathematics for old QCE system
  mutate(
    old_subject_name = case_when(
      subject_name == "General Mathematics" ~ "Mathematics A",
      subject_name == "Mathematical Methods" ~ "Mathematics B",
      subject_name == "Specialist Mathematics" ~ "Mathematics C",
      TRUE ~ paste0("---")
    ),
    .before = subject_name
  ) %>% 
  group_by(subject_type) %>% 
  # Arrange subject names in alphabetical order
  arrange(subject_name) %>% 
  ungroup() %>% 
  select(-subject_type) %>% 
  # Produce HTML table
  kable(caption = "Senior Mathematics subjects in the new QCE system",
        col.names = c("Old subject name","New subject name"),
        booktabs = TRUE,
        align = "c") %>% 
  kable_styling(full_width = FALSE) %>% 
  # Partition subject type
  pack_rows(index = c("Applied Mathematics" = 1,
                      "General Mathematics" = 3)) 
```

There are three main mathematics subjects in the new QCE system, which are broadly equivalent to the Mathematics A, B and C in the old QCE system (Table \@ref(tab:qce-math)). Of the general mathematics subjects, General Mathematics is the least taxing, followed by Mathematical Methods and Specialist Mathematics. Furthermore, Essential Mathematics (applied subject) is introduced in the new system, where it focuses on developing and using mathematical knowledge to investigate real-world problems such as managing money, travel and data, and decision-making using mathematical concept (@essential-math-syllabus). Each school may offer various mathematics programs --- *e.g.* offer two of the three general mathematics subjects, or only offer Essential Mathematics (applied subjects).

Mathematical Methods is often a prerequisite for some university courses, implying that students completing the subject can streamline entry to specific courses in the university. Specialist Mathematics is designed to be taken in conjunction, or on completion of Mathematical methods, as it extends the key ideas studied in that subject. This path is usually recommended for students who wish to undertake further study in mathematics --- such as engineering or science related courses or have strong aptitude in mathematics. 

As an alternative, there is a *safety net* as students may opt for a less challenging mathematics subject such as Essential Mathematics subject (applied subject), as it would also contribute to the student's ATAR score. This subject is usually undertaken by students who do not require mathematics for tertiary education at university of have not been able to attain a pass in Year 10 Core Mathematics. However, it should be noted that only general mathematics subjects or applied mathematics subjects can included in the ATAR, but not both. For instance, it is not possible to incorporate Mathematical Methods (general subject) and Essential Mathematics (applied subject) in a student's ATAR.

### Sciences 

```{r qce-science}
# --- Sciences
mathsci_all %>% 
  filter(subject == "Sciences") %>% 
  # All unique Science subjects
  distinct(subject_name, subject_type) %>% 
  # Include Sciences for old QCE system
  mutate(
    old_subject_name = case_when(
      subject_name == "Psychology" ~ "---",
      subject_name == "Earth & Environmental Science" ~ "Earth Science",
      TRUE ~ subject_name
    ),
    .before = subject_name
  ) %>% 
  group_by(subject_type) %>%
  # Arrange subject names in alphabetical order
  arrange(subject_name, .by_group = TRUE) %>% 
  ungroup() %>% 
  select(-subject_type) %>% 
  # Produce HTML table
  kable(caption = "Senior Science subjects in the new QCE system",
        col.names = c("Old subject name","New subject name"),
        booktabs = TRUE,
        align = "c") %>% 
  kable_styling(full_width = FALSE) %>% 
  # Partition subject type
  pack_rows(index = c("Applied Sciences" = 3,
                      "General Sciences" = 7)) 
```

Unlike mathematics subjects, there are little changes in the subject names. As demonstrated in Table \@ref(tab:qce-science) There are two main changes in science subjects --- 'Psychology' is introduced in the new QCE system and earth science is renamed to Earth and Environmental Science.


# Data Cleaning

To get the dataset ready for the analysis, the dataset is transformed to reproduce that of the new QCE system.

## Joining dataset from old QCE system and new QCE system

**Changing all subject names to match new QCE system**: To combine the datasets relating to the old and new QCE system, the subject names were first matched. As demonstrated in Tables \@ref(tab:qce-math) and \@ref(tab:qce-science), some subjects names were changed in the new QCE system. All subject names in the old system were changed to that of the new system to facilitate the relational join. For example, Mathematics A, B and C were modified to General Mathematics, Mathematical Methods and Specialist Mathematics respectively to match that of the new QCE system. 

**Changing unit 1 and 2, and unit 3 and 4 enrolments to year 11 and year 12 enrolments**: Next, the new QCE system introduces an assessment program consisting of Units 1 and 2. In general, most students complete Units 1 and 2 in Year 11, and Units 3 and 4 are undertaken in year 12. Accordingly, units 1 and 2, and units 3 and 4 are renamed to year 11 enrolments and year 12 enrolments to facilitate the relational join of both datasets corresponding to the old and new QCE system. Once the school and subject information were aligned, both datasets were joined seamlessly.

## Manipulating character strings to match school names

```{r regexps-example}
tibble(
  `School Name (Old QCE system)` = c("St Catherine's Catholic College The Whitsundays (Proserpine (Renwick Road))",
            "Lutheran Ormeau Rivers District School (Lords)",
            "Faith Baptist Christian School (Gladstone)",
            "Rivermount College - Yatala",
            "Carinity Education - Southside"),
  `School Name (New QCE system)` = c("St Catherine's Catholic College The Whitsundays (Proserpine)",
            "Lutheran Ormeau Rivers District School (Pimpama)",
            "Faith Baptist Christian School (Burua)",
            "Rivermount College (Yatala)",
            "Carinity Education - Southside Sunnybank"),
  `Modified School Name` = c("St Catherine's Catholic College The Whitsundays",
                 "Lutheran Ormeau Rivers District School",
                 "Faith Baptist Christian School",
                 "Rivermount College",
                 "Carinity Education")) %>% 
  kable(caption = "Example: Incompatible School names fixed by removing parantheses \"()\" and dash \"-\" ") %>% 
  kable_styling(full_width = FALSE) %>% 
  # Partition subject type
  pack_rows(index = c("Fixed by removing parantheses" = 3,
                      "Fixed by removing dashes" = 2))
```

Regular expressions were utilised to remove school names that did not match in the datasets for the old and new QCE system. An extract of what has been done is shown above (Table \@ref(tab:regexps-example)). Fortunately, schools are uniquely identified with QCAA school ID, easing this process as incompatible school names can be easily identified. In most cases, removing parentheses "()" and dashes "-" relating to suburb solves the issues. 

```{r school-names-error}
tibble(
  `School Name (Old QCE system)` = c("Clairvaux Mackillop College",
                                     "St Aidan's Anglican Girls' School",
                                     "Cloncurry State School P-12",
                                     "Aboriginal & Islander Independent Community School"),
  `School Name (New QCE system)` = c("Clairvaux MacKillop College",
                                     "St Aidan's Anglican Girls School",
                                     "Cloncurry State School",
                                     "Aboriginal and Islander Independent Community School"),
  `Issue (Why school names does not match)` = c("Capital K in 'MacKillop'",
                                                "Extra ' in 'Girls'",
                                                "Extra 'P-12'",
                                                "'&' used instead of 'and'")) %>% 
  kable(caption = "Example: Manually fixing errors due to issues in School Nmaes") %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = c("hovered", "striped"))
```

However, there were cases in which school names have to be recoded manually as the school names were inconsistent. Some of the examples are demonstrated in Table \@ref(tab:school-names-error).


## Missing values in enrolments relate to schools offering subject for Year 11 or Year 12 only

```{r missing-data, fig.cap = "At-a-glance plot of the missing values in the raw dataset, where the pink cells indicate a missing value. Most observations are present, except for three variables. The missing values in year 11 and 12 enrolments relates to schools which offered a subject for year 11 but not for year 12 and vice versa"}
mathsci_all %>% 
  # Convert zeroes back to NA (replicate the raw data)
  mutate(year_11_enrolments = na_if(year_11_enrolments, 0), 
         year_12_enrolments = na_if(year_12_enrolments, 0)) %>% 
  # Display missing values
  naniar::vis_miss(warn_large_data = FALSE,
                   sort_miss = TRUE,
                   ) +
  scale_fill_manual(labels = c("Present (99.2%)", "Missing (0.8%)"),
                    values = c("grey80", "black")) +
  theme(panel.grid = element_blank())
```

```{r eval=FALSE}
# All 0 enrolments in year 11
no_enrolments_year_11 <- mathsci_all %>% 
  filter(year_11_enrolments == 0) %>% 
  nrow()

# Contributed by first prep year cohort
prep_year_2007 <- mathsci_all %>% 
  filter(year_11_enrolments == 0 & completion_year == 2019) %>% 
  nrow()

(prep_year_2007 / no_enrolments_year_11) * 100 
```

```{r, eval=FALSE}
# Extracting all schools with 0 enrolments in year 12
year_12_no_enrolments <- mathsci_all %>% 
  filter(year_12_enrolments == 0) %>% 
  nrow()

# Extract zero year 12 enrolments due to the inception of a new subject for a given school
first_year_no_year_12 <- mathsci_all %>% 
  group_by(qcaa_school_id, subject_name) %>% 
  filter(completion_year == min(completion_year)) %>% 
  filter(year_12_enrolments == 0) %>% 
  nrow()
  
(first_year_no_year_12 / year_12_no_enrolments) * 100
```

Figure \@ref(fig:missing-data) illustrates that most of the observations were present, except for there variables relating to enrolments (`year_11_enrolments` and `year_12_enrolments`) and the Department of Education Centre Code (`doe_centre_code`). 

**Zero enrolments in Year 11**

First, 67.13% of the missing values in year 11 enrolments relate to the 2019 graduating cohort that were part of the Queensland's non-compulsory first Prep Year cohort in 2007. This cohort commenced in 2007 at the current time and will graduate from year 12 in 2019. Therefore, from 2020, every year will be a full cohort of students, implying an additional group of students each year and thus higher expected enrolment for the new QCE system. As this 2007 prep year cohort leaves the schooling system, the enrolments from 2020 will increase considerably as a full cohort will be realised, as will be seen in the later sections.

**Zero enrolments in Year 12**
Next, 71.48% of the zero enrolments in year 12 corresponds to the first year in which a given school introduces a subject. As year 12 enrolments requires students to complete year 11 syllabus, most students may not partake in the subject when the schools first introduce the subject. In further scrutiny, the other schools that have zero enrolments are usually smaller schools (in rural areas) or schools may only offer a subject for year 11 students but not year 12 students in certain years and vice versa. For example, Mossman State High School offered Specialist Mathematics subject in some years --- Offered the subject to Year 11 students of 2020 and Year 12 students of 2021, but not for Year 11 students of 2021 and Year 12 students of 2022 (@mossman-high). 

**Missing Department of Education Centre Code**

Schools that were missing the Department of Education Centre Code refers to schools that existed before 2002. This alludes that these schools may not have been assigned any Department of Education Centre Code. Fortunately, the dataset provides `qcaa_school_id` which have no missing values and can uniquely identify each school, and thus, thee missing values in `doe_centre_code` may be disregarded.

## Revise school postcodes

Errors in school postcodes usually arise form school postcodes codes being reassigned overtime, due to typographical errors, mainly for schools with two or more different locations. These issues were fixed manually by cross checking the correct addresses for the school provided by Google Maps. 


# Exploratory Data Analaysis

```{r}
# Convert to long format for plotting
mathsci_all_long <- mathsci_all %>% 
  pivot_longer(cols = c(year_11_enrolments, year_12_enrolments),
               names_to = "unit",
               values_to = "enrolments")
```

```{r participating-schools, fig.cap = "Total number of participating schools for each subject per year"}
mathsci_all_long %>% 
  group_by(subject_name, completion_year) %>% 
  summarise(total_schools = n(),
            .groups = "drop") %>% 
  ggplot() +
  geom_col(aes(x = completion_year,
               y = total_schools),
           fill = "grey50") +
  facet_wrap(~ subject_name,
             scales = "free_y")
```

Figure \@ref(fig:participating-schools) displays the total number of participating schools for a given year. Some subjects showed rather stable enrolment figures such as Biology and Chemistry, which showed a steady increase in participating schools over the years. Other subjects like Science in Practice and Earth and Environmental Science showed a rather erratic trend, where the first year of Earth and Environmental Science subject showed the largest number of participating schools while Science in Practice subject showed a one-off year (2016) in which the total schools was significantly greater than the other years.


## Total Enrolments for each Subject over the years

```{r}
# Compute total Year 12 enrolments for each year, by subject
total_enrolments <- mathsci_all %>% 
  group_by(completion_year, subject_name, subject) %>% 
  summarise(total_year12_enrolments = sum(year_12_enrolments),
            .groups = "drop") 

total_enrolments %>% 
  ggplot() +
  # Enrolments for all years (old & new system)
  geom_col(aes(x = completion_year,
               y = total_year12_enrolments),
           fill = "grey80") +
  # Enrolments for from 2019 (new system)
  geom_col(aes(x = completion_year,
               y = total_year12_enrolments),
           fill = "grey30",
           data = filter(total_enrolments, completion_year > 2019)) + 
  facet_wrap(~ subject_name,
             scales = "free_y") +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  theme(panel.grid.minor = element_blank(),
        axis.text.x = element_text(angle = 90)) +
  labs(title = "Total Enrolments for each subject per cohort",
       x = "Completion Year",
       y = "Year 12 Enrolments")
```

As mentioned, since the 2007 prep year cohort left the schooling system at the end of 2019, enrolments will be replaced by a full cohort. It is not surprising therefore that all subjects saw a surge in enrolments from 2019 to 2020. Based on a study by Independent Schools Queensland (@isq-enrolments-2020), this resulted in approximately 6.2% (22,050) increase in secondary student enrolments from 2019 and 2020 in independent sectors alone. 

Subjects were introduced at different time frames. Aquatic practices and Marine Science were only introduced in 2014 and 2015 respectively. There was a halt in Agricultural Practices subject in year 2000, before being re-introduced again in 2015. Furthermore, the inception of the new QCE system was two new subjects, Psychology and Essential Mathematics.

## Time plot: Enrolments across the years

```{r time-plot-all}
mathsci_all_long %>% 
  # filter(subject_name == "Earth & Environmental Science") %>% 
  group_by(qcaa_school_id, subject_name, unit) %>%
  # Fill missing years with NA to skip when plotting line plot
  tidyr::complete(completion_year = min(completion_year):max(completion_year),
           fill = list(value = NA)) %>% 
  filter(unit == "year_12_enrolments") %>% 
  ggplot() +
  geom_line(aes(x = completion_year,
                y = enrolments,
                group = qcaa_school_id),
            colour = "grey40",
            alpha = 0.4) +
  stat_summary(aes(x = completion_year,
                   y = enrolments,
                   group = 1),
               fun.y = mean,
               colour = "orange",
               geom = "line",
               size = 1.5) +
  # geom_smooth(aes(x = completion_year,
  #                 y = enrolments,
  #                 group = 1),
  #             alpha = 0.8,
  #             se = FALSE,
  #             colour = "orange") +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  facet_wrap(~ subject_name,
             scales = "free_y") +
  theme(axis.text.x = element_text(angle = 90))
```

Figure \@ref(fig:time-plot-all) displays a spaghetti plot of year 12 enrolments for each subject, with overall fit using the the mean of enrolments for all schools in a given year. Each line represents year 12 enrolments for a single school. For most subjects, some relatively large schools can be identified as their enrolments numbers were significantly higher than most other schools. The year 12 enrolments for these large schools were especially prominent in the later years, where the new QCE system was introduced.

Some subjects that were introduced in the 1990s such as Biology, Chemistry, Physics, General Mathematics and Mathematical Methods showed rather stable enrolment numbers as enrolment trend across schools appears to be proportional to one another. In other words, when there is a general increase (decrease) in enrolments, most schools will show an increase (decrease), as seen by the large cluster of observations. In contrary, Agricultural Earth and Environmental Science, although introduced in the 1990s, did not exhibit such patterns as the enrolment numbers were rather erratic. However, it can be observed that there were significantly less enrolments for these subjects, implying that not many schools offer this subject or the subject is not popular among students.


## It is common for year 11 students to continue pursuing year 12 units

```{r year11-vs-year12, fig.cap = "Year 12 enrolments agianst year 11 enrolments, with a 45° line to indicating a perfect linear relationship"}
mathsci_all %>%
  ggplot() + 
  # Scatter plot
  geom_point(aes(x = year_11_enrolments,
                 y = year_12_enrolments,
                 colour = subject),
             alpha = 0.3,
             colour = "grey30") +
  # Plot 45° line 
  geom_abline(slope = 1,
              intercept = 0,
              size = 1.5,
              colour = "red",
              alpha = 0.5) +
  facet_wrap(subject_name ~ subject,
             scales = "free") +
  labs(title = "Year 12 enrolments against year 11 enrolments,",
       x = "Year 11 enrolments",
       y = "Year 12 enrolments")
```

A scatterplot of year 11 and year 12 are plotted in Figure \@ref(fig:year11-vs-year12), with a 45° line to facilitate the interpretation of the scatter plot, where it indicates a one unit increase in year 11 enrolments is matched with a one-unit increase in year 12 enrolments (*i.e.*perfect linear relationship). As already mentioned, the 0 enrolments in year 11 (as seen on the figure) is attributed to the Queensland's first Prep Year cohort in 2007 while the 0 enrolments in year 12 relates to the year where a school introduces the subject for the very first time (thus, there will be no year 12 students as most students have yet to complete year 11). 

Most subject demonstrates a linear relationship (lie on or **close to the red line**) between year 11 and year 12 students. Intuitively, this is reasonable as a student is likely to continue to complete the year 12 syllabus (unit 3 and 4) after completing his year 11 syllabus (unit 1 and 2). 

Observations **below the red line** may suggest that students have dropped the subject or have taken a gap year. Students are usually recommended to enrol in 6 subjects for senior school (@atar-subjects). A student usually starts with 6 subjects in year 11, before dropping down to 5 subjects in Year 12. However, completing 6 subjects gives the student a "safety net", in the instance where the student did not perform well for a particular subject (noting that ATAR takes the best of 5 subjects). Taking this into account, students appears to be dropping Psychology subject, as Figure \@ref(fig:year11-vs-year12) demonstrates that most year 12 enrolments were below the red 45° line. 

In contrary, observations that lie **above the red line** may indicate that these students may have completed the year 11 (unit 1 and 2) in year 10, and re-enrolled in year 12. Furthermore, students may opt to study at a school of distance education to complete their year 11 (unit 1 and 2) syllabus because of various reasons such as the school not offering year 11 syllabus for a given year.

Some science subjects such as Earth and Environmental Science, Marine science, and Science in Practice displays **heteroscedasticity**, where the larger the cohort size, the higher the rate of students dropping the subject or having more enrolments in year 12. Interestingly, these science subjects have a relatively small number of enrolments. This pattern does not seem to manifest in mathematics subjects.


## Larger schools are associated with lower enrolments in year 12

```{r}
# --- Create data frame showing increase or decrease in year 12 enrolments 

up_or_down <- mathsci_all %>% 
  # Create new variable examining if year 11 enrolments is more than year 12 enrolments
  mutate(slope = if_else(
    year_11_enrolments < year_12_enrolments,
    true = "Upward",
    false = "Downward"),
    slope = as.factor(slope)) %>% 
  # Convert to long format for plotting
  pivot_longer(cols = c(year_11_enrolments, year_12_enrolments),
               names_to = "unit",
               values_to = "enrolments") 

# Remove outliers
up_or_down <- up_or_down %>% 
  group_by(qcaa_school_id) %>% 
  # Zero year 12 students due to introduction of subject
  filter(completion_year != min(completion_year)) %>% 
  ungroup() %>% 
  # Zero year 11 students due to first prep year cohort
  filter(completion_year != 2019) %>% 
  mutate(schoolid_year = paste0(qcaa_school_id, ":", completion_year)) %>% 
  mutate(subject_and_type = paste0(subject, " (", subject_type, ")"))
```

```{r up-or-down, fig.cap = "Parallel Coordinate plot comparing year 11 and year 12 enrolments for a given cohort in a school. The blue (grey) lines represents an increase (decrease) in year 12 enrolments. In general, larger schools appears to have smaller year 12 enrolments, as indicated by numerous grey lines when enrolment numbers are higher"}
ggplot(data = up_or_down,
       aes(x = unit,
           y = enrolments,
           group = schoolid_year)) +
  geom_line(data = filter(up_or_down, slope == "Downward"),
            colour = "grey50",
            alpha = 0.5) +
  geom_line(data = filter(up_or_down, slope == "Upward"),
            colour = "#72bdd4",
            alpha = 0.6) +
  facet_wrap(subject_name ~ subject_and_type,
             scales = "free_y") +
  labs(title = "Parallel coordinates plot highligting the difference betewen year 11 and year 12 enrolments",
       x = "Unit",
       y = "Enrolments")
```

The parallel coordinates plot (Figure \@ref(fig:up-or-down)) allows comparison of the difference between year 11 and year 12 enrolments. The grey line indicates that year 12 enrolments is smaller than year 11 enrolments for a given cohort in a school and conversely, the blue lines represents an increase in enrolments from year 11 to year 12.

In general, larger schools (with relatively high enrolment numbers for a given subject) appears to have smaller year 12 enrolments as compared to year 11 enrolments. This pattern is especially noticeable in Psychology, where most schools with enrolments higher than 150 see a decrease in enrolment numbers from year 11 to year 12. This was not the case for some subjects such as General Mathematics, Chemistry, and Biology.

## Distribution of enrolments for each sector

### Comparing distirbution of subjects

```{r density-plots, "Distributions of enrolments for each subject shown with a density plot, overlaid with a density plot"}
library(ggridges)

mathsci_all_long %>% 
  ggplot() +
  geom_density(aes(x = enrolments),
               fill = "cornsilk") +
  facet_wrap(~subject_name,
             scales = "free")
```

The distribution of enrolments for each subject appears to be right skewed (Figure \@ref(fig:density-plots)). This is possibly attributed to the size of schools, as some schools are significantly larger than others. 

### Comparing enrolments across sectors using boxplot 

```{r boxplot-dist}
# Distribution of enrolments for each subject by sector
mathsci_all %>%
  ggplot() +
  geom_boxplot(aes(x = sector,
                   y = year_12_enrolments,
                   group = sector),
               outlier.alpha = 0.6) +
  facet_wrap(~ subject_name,
             scales = "free")
```

In most subjects, the distribution in enrolments across all sectors were rather similar (Figure \@ref(fig:boxplot-dist). Subjects that were introduced early such as Biology, Chemistry, Specialist Mathematics, and Physics showed stable enrolment numbers, with little variation across the different sectors. As highlighted by the outliers in all subjects, there were schools that has significantly more enrolments, these observations may refer to the larger schools in Queensland. These outliers are considerably prominent, especially in Government schools.

# Predicting enrolments 

## Why the Multilvel Model

At the outset, a standard linear regression model assumes that residuals are independently and identically distributed ($i.i.d$) -- *i.e.* There will be no further correlations (dependence) between measures once predictors are added to the model. Substantively, this suggests that any higher level entities are identical, and can be completely 'pooled' into a single observation. With a longitudinal data, this is often an unreasonable assumption, as temporal data are often characterised by marked dependence over time and response for measurements across time are often related to one another. For instance, the division between the within (*e.g.* schools) and between (*e.g.* between clusters such as district) would be assumed to be equal such that a one-unit increase in enrolments for within effects would match a one unit increase in between-effects, which may be unlikely the case in this context.

Using the multilevel model allows for simultaneous modelling of both intra-school change (*i.e.* how school enrolments are changing overtime) and interindividual change (*i.e.* Differences in temporal change across schools). As the dataset is imbalanced due to schools introducing or ceasing a given subject at different times, the multilevel model is appropriate as it is able to utilise available data from incomplete observations without reducing sample size. 

In general, multilevel models takes on the general form: Repeated measures (level 1) nested within individuals (level 2) and possibly individuals nested within some higher-level clusters (level 3). With respect to the data, level 1 relates to a single measure in time, level 2 relates to the individual schools offering the maths and science subjects and level 3 corresponds to the schools nested within districts or postcodes. As our data is nested within schools and possibly in higher-level clusters, the multilevel model is appropriate.

## Methodology (Building the multilevel model)

As aforementioned, the objective of this report is to predict enrolments in light of the new QCE system.

### 1. Exploring the data with basic linear model within schools {#step-one}
    
A basic linear model within schools provide an at-a-glance visualisation of the enrolment trends within each school. An advantage of this visualisation is that the linear model summarises enrolment trends with only two summary statistics, an intercept and a slope, which is useful for panel data as enrolments can be viewed overtime per school. The intercept conveys a school's enrolments when the subject was first introduced to the school while the slope indicates the school's yearly average increase in enrolments over the period in which the subject is or was running.

### 2. Getting the dataset ready for modelling {#step-two}
    
Each subject encounters different circumstances (*e.g.* new subjects introduced only in 2020), the following steps are the main steps taken to get the dataset for a single subject ready for modelling. However, it should be noted that in some subjects, more or less steps could be taken given the context. 

#### Removing observations with zero enrolments 

```{r year-11-enrolments-all, fig.cap = "Year 11 enrolments, with a vertical line indicating year 2019, where enrolments in most schools dropped to zero due to the 2007 prep year cohort."}
mathsci_all_long %>% 
  filter(unit == "year_11_enrolments") %>% 
  ggplot() +
  geom_line(aes(x = completion_year,
                y = enrolments,
                group = qcaa_school_id),
            alpha = 0.5,
            colour = "grey40") +
  geom_vline(xintercept = 2019,
             colour = "red",
             alpha = 0.8) +
  facet_wrap(~ subject_name) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  labs(title = "Year 11 Enrolments",
       x = "Completion Year",
       y = "Enrolments")
```

Subjects with 0 enrolments for a given cohort will be removed as these enrolment figures will artificially inflate/deflate enrolment numbers. As outlined, most of the zero enrolments in 2019 was due to the completion of the 2007 prep year cohort. These zero enrolments can be seen in Figure \@ref(fig:year-11-enrolments-all), where the vertical red line indicates the year 2019.

By the same token, most year 12 subjects with with zero enrolments relates to the first year schools introduced the subject. In this year, most students would be ineligible to enrol in year 12 units as most year 12 units requires the completion of year 11 units. Furthermore, the other zero enrolments were due to small schools who had little to no enrolments in a particular year.

#### Linearising response variable `enrolments` using log transformation

As seen in the density plots for each subject (Figure \@ref(fig:density-plots)), enrolment numbers are right skewed due to the various school sizes in Queensland. This means that most of the variance captured in the dataset can be attributed to the various school sizes in Queensland. As such, a log transformation will be utilised to allow models to be estimated by the linear mixed models. A log transformation is appropriate in this context as enrolments are by nature, a positive number.

#### Rescale time variable (`completion_year`)

It is often helpful to rescale time variable so the first measurement occasion is the zero point. In this context, the `completion_year` for each subject will be rescaled to 0, where 0 corresponds to the first year in which the subject was introduced. For instance, Specialist Mathematics subject was introduced in 1992, and thus, will be the zero point (variable named `year92`). Rescaling time variable gives the intercept the interpretation of the baseline, or initial status of the dependent variable (*i.e.* 0 as the commencement of the subject)

### 3. Initial model -- Unconditional means (null) model {#step-three}

#### Inherent nested structure

```{r nested-structure, fig.cap = "Nested structure of the dataset"}
knitr::include_graphics(here::here("images/nested-structure.png"))
```

The multilevel model was primarily used because of the underlying nested structure in the dataset; A nested structure occurs when individual data points as one level (*i.e.* schools in this context) appear in only one level of a higher-level variable (*e.g.* school postcodes or *QCAA* district). With a longitudinal data, time predictors will be associated with a single measurement in time (*i.e.* first year in which a school introduces the subject). 

Accordingly, **three potential models** can be identified from the nesting structure above (Figure \@ref(fig:nested-structure)):

(1) Two-level nested structure: Schools
(2) Three-level nested structure: Schools nested within postcodes
(3) Three-level nested structure: Schools nested within **QCAA** districts

Presently, information criteria selection such as AIC dominate the model selection criteria in comparing non-nested multilevel model. This report will follow suit, by comparing the different non-stationary random effects using AIC to select the 'best' initial model.


#### Model specificaiton (and notations)

In a multilevel context, it is often helpful to begin with an unconditional means (null) model where there are no predictors at any level, only an intercept. This model model provides useful information in understanding the structure of the data. It can be utilised to obtain estimates of residuals and intercept variance that allows for assessment of the variation at each level, and in comparing variability in (1) schools within clusters for a level three model or (2) within schools for a level three model. However, before delving into the specifics, all potential models have to be considered. 

For instance, the intraclass correlation coefficient (*ICC* = $\rho_i$) can be computed. *ICC* refers to proportion of variance in the response (`enrolments`) that can be explained by the grouping structure of the hierarchical model; It is often easier to conceptualise it as the correlation between the enrolments of two schools, randomly selected from a cluster or as the same amount of variance explained by those groupings (similar to an $R^2$).

The **three-level** unconditional means model can be expressed as:

- Level one (time point within schools)
  $$Y_{tij} = \pi_{0ij} + \epsilon_{tij}$$
  
- Level two (schools within clusters)
  $$\pi_{0ij} = \beta_{00j} + u_{0ij}$$

- Level three (clusters)
  $$\beta_{00j} = \gamma_{000} + r_{00j}$$

In this case, clusters (*i.e.* in this dataset, districts or postcodes) are considered to be independent, but schools within the same districts and the measurements at different time points for the same school are correlated. If a two-level multilevel model is used, level three can be disregarded.

At level one:

- $y_{tij}$: response variable (`enrolments`) of school $i$ from cluster $j$ at time $t$
- $\pi_{0ij}$: True/average mean of response (`enrolments`) of school $i$ from cluster $j$ across all time points
- $\epsilon_{tij}$: Difference between observed `enrolments` ($y_{tij}$) and mean `enrolments` for school $i$ in district $j$

At level two:

- $\beta_{00j}$: True mean `enrolments` for cluster $j$ across all schools from the given ($j^{th}$) district
- $u_{0ij}$: Difference between `enrolments` of school $i$ from district $j$ from the mean `enrolments` of all schools in district $j$

At level three:

- $\gamma_{000}$: Fixed effects model parameter representing the true mean `enrolments` across all schools, districts and time points
- $r_{00j}$: Describes the difference in enrolments between the mean `enrolments` from all observations in district $j$ and the overall mean enrolments across all districts, schools and time points.

In combining level 1,2 and 3, the composite model can be obtained:

$$\begin{aligned} 

  Y_{ij} & = \pi_{0ij} + \epsilon_{tij} \\
         & = (\beta_{00j} + u_{0ij}) + \epsilon_{tij} \\
         & = (\gamma_{000}) + (r_{00j} + u_{0ij} + \epsilon_{tij})

\end{aligned}$$

The model can be split into two parts. The 'fixed effects' will be represented in the first parentheses of the last expression, usually denoted by $\gamma$ while the 'random effects' will be represented in the second parentheses, denoted by $r$, $u$ and $\epsilon$ components. 

where,

$$\begin{aligned} 

  \epsilon_{tij} & \sim N(0, \sigma^2) \\
  u_{0ij}        & \sim N(0, \tau^2_{00}) \\
  r_{00j}        & \sim N(0, \phi^2_{00}) 
  
\end{aligned}$$

Where,
- $\epsilon_{tij}$: Variance over time within schools
- $\tau^2_{00}$: Variance between schools from the same cluster 
- $\phi^2_{00}$: Variance across clusters 

### 4. Unconditional growth model {#step-four}
    
The unconditional growth model incorporates time as a linear growth at level one (with no predictors at level two and three) to reduce unexplained variability within schools. This model allows for assessing the within-school variability that can be attributed to the systematic changes over time. 

To reduce correlation between the linear components of the time effect, the time variable rescaled. For this report, time variable (`completion_year`) is rescaled to the zero point, that is, the first year in which the school introduced the subject. This gives the intercept the interpretation of baseline or initial status of the enrolments.

#### Model specification

As with the unconditional means model, the unconditional growth model can be expressed as:

- Level one (time point within schools)
  $$Y_{tij} = \pi_{0ij} + \pi_{1ij}year_{tij} + \epsilon_{tij}$$

Where, `year` is the time variable.

- Level two (schools within clusters)
  $$\pi_{0ij} = \beta_{00j} + u_{0ij} \\
    \pi_{1ij} = \beta_{10j} + u_{1ij}$$
  
- Level three (clusters)
  $$\beta_{00j} = \gamma_{000} + r_{00j} \\
    \beta_{10j} = \gamma_{100} + r_{10j}$$
    
    
As compared to the null-model, the between-school and between-clusters variability are now partitioned into variability in initial status ($\tau^2_{00}$ and $\phi^2_{00j}$) and variability in rates of change ($\tau^2_{10}$ and $\phi^2_{10}$); *i.e.*

At level one:

- The level one trajectory for school $i$ in district $j$ is assumed to be linear, with intercept $\pi_{0ij}$ and slope (growth rate) $\pi_{1ij}$ 
- $\epsilon_{tij}$ captures the deviation between the true growth trajectory and the observed values (`enrolments`)

At level two:

- $\beta_{00}$ represents the true intercept and $\beta_{10}$ represents the true mean slope for all school $i$
- The random effects $u_{0ij}$ and $u_{1ij}$ captures the deviation between school $i$'s true growth trajectory and the mean intercept for and slope for school $i$
  - The deviations in intercept and slope at level two are allowed to be correlated through the covariance parameter $\tau_{01}$
  
At level three:

- $\gamma_{000}$ is the true mean intercept while $\gamma_{100}$ is the true mean yearly growth rate for over all schools
- $r_{00j}$ and $r_{10j}$ captures the deviation between school $i$ true overall growth trajectory and population mean intercept and slope

In combining the levels, the full composite model may be obtained:

$$\begin{aligned}
  Y_{tij} &= \pi_{0ij} + \pi_{1ij}year_{tij} + \epsilon_{tij} \\
          &= (\beta_{00j} + u_{0ij}) + (beta_{10j} + u_{1ij})year_{tij} +  \epsilon_{tij} \\
          &= (\gamma_{000} + r_{00j} + u_{0ij})  + (\gamma_{100} + r_{10j} + u_{1ij})year_{tij} + \epsilon_{tij} \\
          &= [\gamma_{000} + \gamma_{100}year_{tij}] + [r_{00j} + u_{0ij} + \epsilon_{tij} + (r_{10j} + u_{1ij})year_{tij}]
  
\end{aligned}$$

With, $\epsilon_{ijk} \sim N(0, \sigma^2)$,

$$\left( \begin{matrix} u_{0j} \\ u_{1j} \end{matrix} \right) 
  \sim N 
  \left( 
    \begin{matrix} 0 \\ 0 \end{matrix} 
    \begin{matrix} , \end{matrix}
    \begin{matrix} \tau^2_{00} & \tau_{01} \\ \tau_{01} & \tau^{2}_{10} \end{matrix}
  \right)$$
  
$$\left( \begin{matrix} r_{00j} \\ r_{10j} \end{matrix} \right) 
  \sim N 
  \left( 
    \begin{matrix} 0 \\ 0 \end{matrix} 
    \begin{matrix} , \end{matrix}
    \begin{matrix} \phi^2_{00} &  \\ \phi_{01} & \phi^{2}_{10} \end{matrix}
  \right)$$
  

### 5. Dealing with boundary issues, if any

The multilevel models may encounter boundary constraint, especially when random slopes are introduced at level two and three. This singular fit error occurs as correlation coefficients between two error terms are at the 'boundary' of the allowable values $[1,1]$. In this report, the error is an indication of overfitting of the model (@glmm-faq) -- That is, the random effects structure proves to be too complex to be supported by the data. 

Naturally, this suggests that the model requires re-parameterisation by altering to feature different parameters. This report considers simplifying the model by removing level three error terms ($r_{10j}$); which effectively removes two parameters 
  (1) Variance for $r_{10j}$ and
  (2) Correlation between $r_{01j}$ and $r_{10j}$
  
With respect to the unconditional growth model, the model is simplified by setting the error term $r_{10}j = 0$ (and therefore $r_{10} = 0$) at level three:

$$\beta_{00j} = \gamma_{000} + r_{00j} \\ \beta_{10j} = \gamma_{100}$$
 
This implies that the model's error assumption at level three will turn into a univariate (as opposed to a multivariate) normal distribution.
Furthermore, this will also imply that level-three (*e.g.*) clusters will be associated with the same growth rate; In other words, each cluster will have the same rate of change in enrolments for each year. In most cases, removing these parameters will have an insignificant impact on the fixed effects. Therefore, the benefit of this approach is that it will lead to a more parsimonious model that is not over-fitted and free from any boundary constraints.

### 6. Adding fixed fixed effects and comparing potential models with criterion-based approach {#step-six}

#### Adding `sector` and `unit` as fixed effects

In general, there are two types of predictors which may be added to the longitudinal model
  (1) Time varying (level 1): predictors that are associated with a specific measurement of time
  (2) Time invariant (level 2 or higher): Predictors associated with schools or clusters measured only at one point in time
  
At this point, the model only has a dedicated time variable that makes the multilevel longitudinal, with no other predictors added. With reference to Table \@ref(tab:data-description), this report will consider school-specific and subject-specific variables as there are no cluster-specific (district or postcode information) variables. To be specific, two time-invariant predictors (`sector` and `unit`) will be added to the model as fixed effects. To be noted, these categorical variables will not be added as random effects as there is not enough random-effect levels (*e.g.* blocks) for these predictors. As a rule of thumb, there should be more than 5 or 6 levels at a minimum (@glmm-faq). Furthermore, adding another level to the model may overcomplicate interpretations.

#### Forward Stepwise Approach to select the best model

```{r, fig.align = "center"}
knitr::include_graphics(here::here("images/fixed-effects.png"))
```


In adding `sector` and `unit` into the model, there will be a handful of potential models (*e.g.* three-way interactions and two-way interactions, removing three-way interactions etc.). This report considers a forward stepwise approach, where the largest possible model (all possible combinations of fixed effects) will be fitted, before removing the fixed effects sequentially (one after another). The AIC will then be recorded for each model; Noting that models will be fitted with with maximum likelihood estimates rather than the default restricted maximum likelihood estimates (REML) as REML will generally lead to erroneous results as the fixed effects change (@faraway2016extending). The model with the lowest AIC will be deemed the "best" model, based on the fixed effects.

### 7. Test random effects using parametric bootstrap {#step-seven}

The parametric bootstrap will be utilised to examine if simplified (smaller) version of model (with fewer random effects) is preferred. For a three-level multilevel model, this involves removing the random slope ($r_{10j}$) in the larger (proposed) model at level-three to create the smaller model. Removing $r_{10j}$ is equivalent to setting $\phi_{01} = 0$ and $\phi_{10} = 0$. In other words, the parametric bootstrap tests if the variance of a random effect $r_{10j}$, is in fact 0. 

The parametric bootstrap better approximates the correct $p$-value for the corresponding likelihood ratio test by simulating under the null hypothesis, especially when the actual likelihood ratio test statistic is at the vicinity of the critical value of the (wrong) reference distribution. The standard $\chi^2$ asymptotic are not used as it is proven to be produce a 'too conservative' test, where the $p$-values are usually too large and not rejected enough (@faraway2016extending).

#### Process 

In conducting the parametric bootstrap involving variance terms at the boundary, the null and alternative hypothesis can be written as:
$$H_0: \phi^2_{00} = \phi_{01} \ne 0 \\ H_A: \phi^2_{00} = \phi_{01} = 0 $$

(1) Begin by fitting both (full and smaller) models to the actual data with maximum likelihood estimates to obtain the actual likelihood ratio test statistic ($2 \times logL(\text{full model}) - logL(\text{reduced model})$). This will be called the "actual (observed) likelihood ratio test statistic".

(2) Using the smaller model, obtain estimated fixed effects & variance components (**parametric**).

(3) Use estimated fixed effects and variance components to generate pseudo-data from the null model -- *i.e.* regenerate a new set of response (log(`enrolments`)) with its associated fixed effects for each observation (**bootstrap**).

(4) Fit both smaller and reduced model to the new pseudo-data.

(5) Compute likelihood ratio test statistic comparing both models.

(6) Repeat steps 2-4 for a large number of times (this report simulates $B = 1,000$ bootstrap samples).

(7) The estimated $p$-value is computed by finding the proportion of likelihood ratio test statistic that exceeds the actual (observed) value in step (1). That is, the chance of observing the large (small) actual likelihood test statistic or check if the large (small) actual test statistic was a rare occurrence.

**Note:**: Code is provided by fabians (@bootstrapANOVA); Some modifications were made to the original code to be aligned with the analysis.

In conducting the parametric bootstrap, a histogram of the likelihood ratio test statistic will then be implemented to visualise the results (can be compared with a $\chi^2$-distribution with 2 degrees of freedom). If the null hypothesis is rejected at the 5% level (*i.e.* p-value < 0.05), it indicates that the smaller model is not correct and the full model will be selected.

### 8. Parametric bootstrap to conduct Confidence interval {#step-eight}

With our final model, confidence intervals can be constructed for the parameters; This can be done via the `confint(method = "boot")` function. However, it is always better to get a more intuitive understanding of what the function is doing under the hood.

(1) Simulate data from the proposed model  

(2) Refit the model using the new responses from the simulated data and estimate the parameters  

(3) Repeat steps 1 and 2 for a larger number of times, storing the results each time  

(4) Use quantiles of bootstrapped estimates to compute the estimated intervals  

- Like any other confidence interval, the output can be interpreted as -- if the procedure was repeated many times over, the true value will lie within the interval 95% of the time. 

- This confidence interval can be used to reinforce the idea that the larger model is better by checking if the variance parameters does not include 0, suggesting that the random effects are significant at the 5% level.

### 9. Interpreting the final model {#step-nine}

#### Fixed effects

Fixed effects are functions of the covariates that accounts for the differences over time, 'controlling out' higher-level differences and processing the distinctive specific characteristics of higher-level units (@bell2015explaining). Fixed effects introduces a separate parameter for each group -- equivalent to introducing dummy variables for each higher-level entity (less a reference category) -- where each group are independent and has its own individual characteristics. As will be demonstrated, it allows for analysing the trends in enrolments between the different sectors (Catholic, Independent and Government) and units (year 11 and year 12) and the coefficients may be interpreted like a standard regression model.

#### Random effects

With the higher-level variance being 'controlled out' by the fixed effects, the random effects framework allows for heterogeneity to not only be corrected, but explicitly modelled (@bell2015explaining). The random effects expresses the variation between all schools, which assumes that the higher-level entities comes from random draws of a normal distribution -- which the variance is estimated by the model -- and can itself be interpretable and relevant. This implies that random effects induces  a correlation between schools at the same level (*e.g.* schools in the same district).

### 10. Model Diagnostics

- QQ plot
- Fitted vs residuals to check for heteroscedasticity

## Limitations

- Different optimisers are used, no change in interpretation, only more computationally intensive (@glmm-faq). In most cases, "bobyqa" and "Nelder_Mead" optimiser is used.

Some limitations to this report 
- No proportions dataset 
- Only indicator variables are available

# Acknowledgement

The programming language used to analyse trends in enrolments for senior secondary (Year 11 and Year 12) mathematics and science subjects in Queensland is R (4.0.2) [@R], and the platform used for running R language is RStudio (1.4.1717) [@RStudio].

The following packages have been included in our Rmd file.

-   package tidyverse (1.3.0) [@tidyverse],
-   package broom (0.7.9) [@broom]
-   package broom.mixed (0.2.7) [@broom-mixed]
-   package colorspace [@colorspace]
-   package here (1.0.1) [@here]
-   pacakge kableExtra (1.3.4) [@kableExtra]
-   package knitr(1.36) [@knitr]
-   package lme4 (0.6.7) [@lme4]
-   package patchwork (1.1.1) [@patchwork]
-   package naniar (0.6.0) [@naniar]

# References





