---
title: "Multilevel Model for Essential Mathematics"
author: "Brendi Ang"
date: "17/10/2021"
output: 
  bookdown::html_document2:
    theme: flatly
    toc: true
    number_sections: false
---

```{r ess-math-setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(broom)
library(broom.mixed)
library(colorspace)
library(kableExtra)
library(lme4)
library(patchwork)

ggplot2::theme_set(theme_bw())

select <- dplyr::select
```

```{r, include=FALSE, warning=FALSE}
# Read-in data
mathsci_all <- read_csv(here::here("data/mathsci_all.csv"),
                        col_types = cols(doe_centre_code = col_factor()))

# Convert data types
mathsci_all <- mathsci_all %>% 
  mutate(across(.cols = c(qcaa_subject_id, 
                          subject_type,
                          qcaa_school_id,
                          sector,
                          school_postcode
                          ),
                ~ as.factor(.x))) 
```

## Essential Mathematics

```{r}
ess_math <- mathsci_all %>% 
  filter(subject_name == "Essential Mathematics")

ess_math_long <- ess_math %>% 
  pivot_longer(cols = year_11_enrolments:year_12_enrolments,
               names_to = "unit",
               values_to = "enrolments") 
```

## Exploring the dataset with basic linear model for each school

```{r ess-math-eda, fig.cap = "Basic linear model for 20 randomly selected schools to provide an at-a-glance visualisation of enrolment trends within schools for biology subject"}

# Fit a linear model for 20 random sampled schools
set.seed(7367)

ess_math_long %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, size = 20),
         enrolments > 0) %>% 
  ggplot(aes(x = completion_year,
             y = enrolments)) +
  geom_point() +
  stat_smooth(method = "lm",
              colour = "orange") +
  facet_wrap(~ qcaa_school_id) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Completion year",
       y = "Enrolments",
       title = "Linear fit for 20 randomly selected schools")
```

As [stated above](#new-subjects), Essential Mathematics is one of the new subject introduced in the QCE system. Thus, there are only observations for three years, spanning from 2020 to 2022, as shown in Figure \@ref(fig:ess-math-eda). The various sizes of schools can be seen in the plot, where schools 589, 631, 753 (bottom-right) have relatively low enrolments as compared to school 40 or school 88 (top-right). School 484 introduced the school in 2020, but discontinued offering the subject since.

## Getting the data ready for modelling

### Linearise response variable using log transformation

```{r}
p1 <- ggplot(ess_math_long, aes(enrolments)) +
      geom_histogram(binwidth = 15,
                     fill = "white",
                     colour = "black") +
      geom_density(aes(y = 15 * ..count..),
                   fill = "steelblue",
                   alpha = 0.4) +
    labs(title = "Before log transformation",
         x = "Enrolments",
         y = "Density")

p2 <- ggplot(ess_math_long, aes(log(enrolments))) +
      geom_histogram(binwidth = 0.3,
                     fill = "white",
                     colour = "black") +
      geom_density(aes(y= 0.3 * ..count..),
                   fill = "steelblue",
                   alpha = 0.4) +
  labs(title = "After log transformation",
       x = "Log Enrolments",
       y = "Density")

p1 / p2
```

The enrolments were right skewed, which is likely to be attributed to the various school sizes (as seen in Figure \@ref(fig:ess-math-eda)). A log transformation was implemented to the response variable (*i.e.* `enrolments`) to allow the the multilevel model to better capture the enrolment patterns. 

```{r}
# ----- Cleaning script

ess_math <- ess_math %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove schools that offer subject in one of Year 11 or Year 12 only
  filter(year_12_enrolments != 0,
         year_11_enrolments != 0)

ess_math_long <- ess_math_long %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove schools that offer subject in one of Year 11 or Year 12 only
  filter(enrolments != 0) %>% 
  # Recentre year
  mutate(year20 = completion_year - min(completion_year),
         .before = completion_year) %>% 
  # Log transformation of response variable
  mutate(log_enrolments = log(enrolments))
```

## Unconditional means model

```{r}
# ----- Fit possible null model

# Two-level: Within schools
model0.0 <- lmer(log_enrolments ~ 1 + (1 | qcaa_school_id),
                 data = ess_math_long)

# Three-level: Schools nested within postcodes
model0.1 <- lmer(log_enrolments ~ 1 + (1 | school_postcode/qcaa_school_id),
                 data = ess_math_long)

# Three-level Schools nested within districts
model0.2 <- lmer(log_enrolments ~ 1 + (1 | qcaa_district/qcaa_school_id),
                 data = ess_math_long)
```

```{r ess-math-init-models}
# Obtain AIC for each null model
model0_AIC <- AIC(model0.0, model0.1, model0.2) 

# Change row names 
rownames(model0_AIC) <- c("Model0.0: Within schools",
                          "Model0.1: Schools nested within postcodes",
                          "Model0.2: Schools nested within districts")

# Show AIC for each candidate model
model0_AIC %>% 
  arrange(AIC) %>% 
  kable(caption = "AIC values for all candidate models for Essential Mathematics") %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = c("hovered", "striped"))
```

Referring back to [step 3](#step-three), three candidate models are fitted, with the AIC shown in Table \@ref(tab:ess-math-init-models). `Model0.2`, corresponding to having schools nested within districts is the best model, with optimised (lowest) AIC and will be used in the subsequent analysis.

### Intraclass correlation ($ICC$)

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model0.2)

cat("Random effects:", "\n")

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

cat("\n","Fixed effects:", "\n")
# Extract fixed effects coefficient
coef(summary(model0.2))

# Print grouping structure
cat("\n",
    "Number of schools (level-two group) =",
    summary(model0.2)$ngrps[1], "\n", 
    "Number of district (level-three group) =",
    summary(model0.2)$ngrps[2])
```

This model takes into account 458 schools nested in 13 districts. In a three-level multilevel model, two intraclass correlations can be obtained using the model summary output above:

The **level-two ICC** relates to the correlation between school $i$ from a certain district $k$ in time $t$ and in time $t^*$:

$$\text{Level-two ICC} = \frac{\tau^{2}_{00}}{\tau^{2}_{00} + \phi^{2}_{00} + \sigma^2} = \frac{1.1484}{(1.1484 + 0.0477 + 0.1140)} = 0.8766$$

This can be conceptualised as the correlation between enrolments of two random draws from the same school at two different years. In other words, 87.66% of the total variability is attributable to the differences between schools from the same district rather than changes over time within schools.

The **level-three ICC** refers to the correlation between different schools $i$ and $i^*$ from a specific school $j$. 

$$\text{Level-three ICC} = \frac{\phi^2_{00}}{\tau^2_{00} + \phi^2_{00} + \sigma^2} = \frac{0.0477}{(1.1484 + 0.0477 + 0.1140)} = 0.0364$$

Similarly, it can be inferred that the correlation between enrolments of two randomly selected schools from different districts are 3.64%, where the total variability can be attributed to the difference between districts.


## Unconditional Growth model

```{r}
# Unconditional growth model
model1.0 <- lmer(log_enrolments ~ year20 + 
                (year20 | qcaa_district:qcaa_school_id) + 
                (year20 | qcaa_district),
                REML = TRUE,
                data = ess_math_long)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model1.0)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model1.0))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model1.0)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model1.0)$ngrps[2])
```

The unconditional growth model adds the systematic changes over time, the model specification can be found in [step 4](#step-four). This allows for assessing within-school variability which can be attributed to the linear changes over time. Based on the model output:

- $\pi_{0ij}$ = 3.7837: Initial status for school $i$ in district $j$ (*i.e.* expected log enrolments when time = 0)
- $\pi_{1ij}$ = 0.0582: Growth rate for school $i$ in district $j$
- $\epsilon_{tij}$ = 0.0732: Variance in within-school residuals after accounting for linear growth overtime

Essential Mathematics was first introduced in 2020, and schools are expected to have 43.9785 ($e^{3.7837}$), on average. Furthermore, enrolments were expected to increase by 5.9937\% ($e^{0.0582092} - 1) \times 100$) every year. The estimated within-school variance decrease by 35.7577\% (0.1140 to 0.0732362), implying that 35.7577\% of the within-school variability can be explained by the linear growth over time.

## Testing fixed effects

```{r}
model4.0 <- lmer(log_enrolments ~ year20*sector*unit +
                (year20 | qcaa_district:qcaa_school_id) + 
                (year20 | qcaa_district),
                REML = FALSE,
                data = ess_math_long)

# ----- Specify all models with different fixed effects

# --- Remove three-way interaction

model4.1 <- update(model4.0, . ~ . - sector:unit:year20)

# --- Remove two two-way interaction

model4.2 <- update(model4.1, . ~. - sector:year20 - unit:year20)

model4.3 <- update(model4.1, . ~. - unit:sector - sector:year20)

model4.4 <- update(model4.1, . ~. - unit:sector - unit:year20)

# --- Remove one two-way interaction

# Remove sector:unit interaction
model4.5 <- update(model4.1, . ~ . - sector:unit)

# Remove sector:year20 interaction
model4.6 <- update(model4.1, . ~ . - sector:year20)

# Remove unit:year20 interaction
model4.7 <- update(model4.1, . ~ . - unit:year20)

# --- No interactions

# Include 3 fixed effects
model4.8 <- update(model4.1, . ~. - unit:year20 - sector:year20 - unit:year20)

# Remove unit fixed effects
model4.9 <- update(model4.8, . ~. - unit)

# Remove sector fixed effects
model4.10 <- update(model4.8, . ~. - sector)
```


```{r}
# ANOVA test
model_anova <- anova(
  model4.0,
  model4.1,
  model4.2,
  model4.3,
  model4.4,
  model4.5,
  model4.6,
  model4.7,
  model4.8,
  model4.9,
  model4.10
)


model_anova %>% 
  as_tibble() %>% 
  select(npar, AIC, BIC, logLik) %>% 
  mutate(model = rownames(model_anova),
         .before = npar) %>% 
  arrange(AIC)
```
As detailed in [step 6](#step-six), level-two predictors (`sector` and `unit`) are added to the model. The largest possible model will be fitted, before removing each fixed effect one by one whilst recording the AIC for each model. `model4.0` corresponds to the largest model while `model4.10` is the smallest possible model. The model with the optimal (lowest) AIC is the largest possible model `model4.0`, and will be used in subsequent sections.

## Parametric bootstrap to test random effects

```{r}
bootstrapAnova <- function(mA, m0, B = 1000){
  oneBootstrap <- function(m0, mA){
    
    # Regenerate new set of response with the null model
    d <- drop(simulate(m0))
    
    # Fit both null and full model to the new data
    m2 <- refit(mA, newresp=d)
    m1 <- refit(m0, newresp=d)
    
    # Return chisq test statistic
    return(anova(m2,m1)$Chisq[2])
  }  
  
  # Conduct test 1,000 times and
  # Store chisq test statistic for each iteration
  nulldist <- replicate(B, oneBootstrap(m0, mA))
  
  # chisq statistic based on the proposed and null model
  ret <- anova(mA, m0)
  
  # Change p-value to bootstrap p-value
  # Proportion of times simulated chisq statistic > actual chisq test statistic
  ret$"Pr(>Chisq)"[2] <- mean(ret$Chisq[2] < nulldist)
  
  # Change name from Pr(>Chisq) to Pr_boot(>Chisq)
  names(ret)[8] <- "Pr_boot(>Chisq)"
  
  # Change heading of model output
  attr(ret, "heading") <- c(attr(ret, "heading")[1], 
    paste("Parametric bootstrap with", B,"samples."),
    attr(ret, "heading")[-1])
  
  attr(ret, "nulldist") <- nulldist
  return(ret)
}
```

```{r}
# Best model based on AIC and BIC

# Proposed model
balt <- lmer(log_enrolments ~ year20*sector*unit +
               (year20 | qcaa_district:qcaa_school_id) +      
               (year20 | qcaa_district) ,
             REML = FALSE,
             data = ess_math_long)

# Null model
bnull <- lmer(log_enrolments ~ year20*sector*unit + 
               (year20 | qcaa_district:qcaa_school_id) +      
               (1 | qcaa_district),
              REML = FALSE,
              data = ess_math_long)

actual <- 2*(logLik(balt) - logLik(bnull))
```

```{r, eval=FALSE, warning=FALSE, message=FALSE}
bootstrapLRT <- bootstrapAnova(mA = balt,
                               m0 = bnull, 
                               B = 1000)

save(bootstrapLRT, file = here::here("data/bootstrapLRT/ess-math.rda"))
```

```{r ess-math-bootstrapLRT-tab}
# Load bootstrap likelihood ratio test output
load(here::here("data/bootstrapLRT/ess-math.rda"))

as_tibble(bootstrapLRT) %>% 
  kable(caption = "Parametric Bootstrap to compare larger and smaller, nested model") %>% 
  kable_styling(full_width = FALSE)
```


```{r ess-math-bootstrapLRT-plot, fig.cap = "Histogram of likelihood ratio test statistic, with a red vertical line indicating the likelihood ratio test statistic for the actual model"}
nullLRT = attr(bootstrapLRT, "nulldist")
x = seq(0, max(nullLRT), length = 100)
y = dchisq(x, 2)

nullLRT.1 <- as.data.frame(cbind(nullLRT = nullLRT, x = x, y = y))

ggplot(nullLRT.1) +
  geom_histogram(
    aes(x = nullLRT, y = ..density..),
    bins = 25,
    color = "black",
    fill = "white"
  ) + 
  geom_vline(xintercept = actual, 
             size = 1,
             colour = "red") +
  geom_line(aes(x = x, y = y)) +
  labs(y = "Density",
       x = "Likelihood Ratio Test Statistics from Null Distribution") 
```

The parametric bootstrap is used to approximate the likelihood ratio test statistic to produce a more accurate p-value by simulating data under the null hypothesis (detailed explanation can be found in [step 7](#step-seven). Figure \@ref(fig:ess-math-bootstrapLRT-plot) displays the likelihood ratio test statistic from the null distribution, with the red line representing the likelihood ratio test statistic using the actual data. 

The p-value of 25.6\% (Table \@ref(tab:ess-math-bootstrapLRT-tab)) indicates the proportion of times in which the bootstrap test statistic is greater than the observed test statistic. The large estimated $p$-value is 0.256 < 0.05 fails to reject the null hypothesis at the 5% level, indicating that the smaller model (without random slope at level three) is preferred.

## Confidence interval

```{r}
# Fit best model with restricted maximum likelihood estimates
model_f <- lmer(log_enrolments ~ year20*sector*unit +
               (year20 | qcaa_district:qcaa_school_id) +      
               (1 | qcaa_district) ,
             REML = TRUE,
             data = ess_math_long)
```

```{r, eval=FALSE}
confint_f <- confint(model_f,
        method = "boot",
        oldNames = FALSE)

save(confint_f, file = here::here("data/confint/ess-math.rda"))
```

```{r ess-math-confint}
load(here::here("data/confint/ess-math.rda"))

as_tibble(confint_f) %>% 
  mutate(var = rownames(confint_f),
         .before = `2.5 %`) %>% 
  kable(caption = "95% confidence intervals for fixed and random effects in the final model") %>% 
  kable_styling(full_width = FALSE)
```

The parametric bootstrap is utilised to construct confidence intervals (as detailed in [step 8](#step-eight)). If the confidence intervals for the random effects does not include 0, it provides statistical evidence that the p-value is less than 0.5. In other words, it suggests that the random effects and the correlation between the random effects are significant at the 5% level. The 95% confidence interval is shown above (Table \@ref(tab:ess-math-confint)), and the random effects all exclude 0, further reiterating that they are statistically significant at the 5% level. 

## Interpreting final model

### Fixed effects

- Level one (measurement variable)
$$Y_{tij} = \pi_{0ij} + \pi_{1ij}year20_{tij} + \epsilon_{tij}$$

- Level two (schools within districts) 
  $$\pi_{0ij} = \beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + \beta_{03j}sector_{ij}unit_{ij} + u_{0ij} \\ 
    \pi_{1ij} = \beta_{10j} + \beta_{11j}sector_{ij} + \beta_{12j}unit_{ij} + \beta_{03j}sector_{ij}unit_{ij} + u_{1ij}$$

- Level three (districts)
  $$\beta_{00j} = \gamma_{000} + r_{00j} \\
    \beta_{01j} = \gamma_{010} + r_{01j} \\
    \beta_{02j} = \gamma_{020} + r_{02j} \\
    \beta_{03j} = \gamma_{030} + r_{03j} \\
    \beta_{10j} = \gamma_{100} \\
    \beta_{11j} = \gamma_{110} \\
    \beta_{12j} = \gamma_{120} \\ 
    \beta_{13j} = \gamma_{130} $$

Therefore, the composite model can be written as

$$\begin{aligned} 
Y_{tij} =\ &\pi_{0ij} + \pi_{1ij}year92_{tij} + \epsilon_{tij} \\

        =\ & (\beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + \beta_{03j}sector_{ij}unit_{ij} + u_{0ij}) + \\
           & (\beta_{10j} + \beta_{11j}sector_{ij} + \beta_{12j}unit_{ij} + \beta_{13j}sector_{ij}unit_{ij} + u_{1ij})year20_{tij} + 
           \epsilon_{tij} \\
           
        =\ & \left[\gamma_{000} + r_{00j} + (\gamma_{010} + r_{01j})sector_{ij} + (\gamma_{020} + r_{02j})unit_{ij} +
             (\gamma_{030} + r_{03j})sector_{ij}unit_{ij}  + u_{0ij} \right] + \\
            & \left[\gamma_{100} + \gamma_{110}sector_{ij} + \gamma_{120}unit_{ij} + \gamma_{130}sector_{ij}unit_{ij} + u_{1ij}
              \right]year20_{tij} + \epsilon_{tij} \\
              
        =\ & \left[\gamma_{000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{030}sector_{ij}unit_{ij} + 
             \gamma_{100}year20_{tij} + \gamma_{110}sector_{ij}year_{tij} + \gamma_{120}unit_{ij}year_{tij} +             
             \gamma_{130}sector_{ij}unit_{ij}year_{tij} \right] \\
           & \left[r_{00j} + r_{01j}sector_{ij} + r_{02j}unit_{ij} + r_{03j}sector_{ij}unit_{ij} + u_{0ij} + u_{1ij}year20_{tij} + \epsilon_{tij} \right] 
            
\end{aligned}$$ 

```{r}
# Extract fixed effects for final model
fixef_f <- fixef(model_f)

# \gamma_{000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{030}sector_{ij}unit_{ij} + 
# \gamma_{100}year20_{tij} + \gamma_{110}sector_{ij}year_{tij} + \gamma_{120}unit_{ij}year_{tij} +             
# \gamma_{130}sector_{ij}unit_{ij}year_{tij}

# Catholic (unit 11)
fit_cat_unit11 <- fixef_f[[1]] + fixef_f[[2]] * c(0:5)

# Catholic (unit 12)
fit_cat_unit12 <-
  fixef_f[[1]] + fixef_f[[5]] + fixef_f[[2]] * c(0:5) + fixef_f[[8]] * c(0:5)

# Government (unit 11)
fit_gov_unit11 <-
  fixef_f[[1]] + fixef_f[[3]] + fixef_f[[2]] * c(0:5) + fixef_f[[6]] * c(0:5) 

# Government (unit 12)
fit_gov_unit12 <-
  fixef_f[[1]] + fixef_f[[3]] + fixef_f[[5]] + fixef_f[[9]] + fixef_f[[2]] * c(0:5) + fixef_f[[6]] * c(0:5) + 
  fixef_f[[8]] * c(0:5) + fixef_f[[11]] * c(0:5)
  
# Independent (unit 11)
fit_ind_unit11 <-
  fixef_f[[1]] + fixef_f[[4]] + fixef_f[[2]] * c(0:5) + fixef_f[[7]] * c(0:5) 
  
# Independent (unit 12)
fit_ind_unit12 <-
  fixef_f[[1]] + fixef_f[[4]] + fixef_f[[5]] + fixef_f[[10]] + fixef_f[[2]] * c(0:5) + fixef_f[[7]] * c(0:5) + 
  fixef_f[[8]] * c(0:5) + fixef_f[[12]] * c(0:5)
```

```{r}
fit_f <-
  tibble(
    # Unit 11
    Catholic_unit11 = fit_cat_unit11,
    Government_unit11 = fit_gov_unit11,
    Independent_unit11 = fit_ind_unit11,
    # Unit 12
    Catholic_unit12 = fit_cat_unit12,
    Government_unit12 = fit_gov_unit12,
    Independent_unit12 = fit_ind_unit12,
    # Time variables
    year92 = 0:5,
    completion_year = year92 + 2020
  )

# Convert to long form for plotting
fit_f <- fit_f %>% 
  pivot_longer(cols = Catholic_unit11:Independent_unit12,
               names_to = "sector_unit",
               values_to = "fit") 

fit_f <- fit_f %>% 
  # Separate sector and unit into two variables
  separate(sector_unit, 
           into = c("sector", "unit"), 
           sep = "_",
           remove = FALSE) # Keep old variable for grouping in plot
```



```{r ess-math-fixef, fig.cap = "Fixed effects of the final model for Essential Mathematics"}
fit_f %>% 
  ggplot(aes(x = completion_year,
             y = fit,
             group = sector_unit,
             colour = sector)) +
  geom_line(aes(linetype = unit),
            size = 1,
            alpha = 0.7) +
  scale_colour_discrete_qualitative() +
  labs(title = "Fixed effects of final model",
       x = "Completion Year",
       y = "Predicted log enrolments") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 90)) +
  scale_x_continuous(breaks = seq(2020, 2025, by = 1),
                     labels = seq(2020, 2025, by = 1)) 
```

With a three-way interaction, it is easier to visualise the fixed effects (Figure \@ref(fig:ess-math-fixef)). All sectors demonstrated the same trend with units, where unit 11 showed a larger increase in enrolments, on average. This implies that over the years, more students are enrolling in unit 11 than unit 12.

### Random effects

```{r}
# Random effects for schools within districts
ranef_school_f <- as_tibble(ranef(model_f)) %>%
  filter(!grp %in% unique(mathsci_all$qcaa_district)) %>% 
  separate(
    col = grp,
    into = c("qcaa_district", "qcaa_school_id"),
    sep = ":",
    remove = FALSE
  ) %>% 
  # Rename intercept and slope names
  mutate(term = if_else(term == "(Intercept)",
                        true = "Random Intercept",
                        false = "Random Slope")) 

# Random effects for between districts
ranef_district_f <- as_tibble(ranef(model_f)) %>% 
  filter(grp %in% unique(mathsci_all$qcaa_district)) %>% 
  group_by(term) %>% 
  rename(qcaa_district = grp) %>% 
  # Rename intercept and slope names
  mutate(term =  as.character(term),
         term = factor(if_else(
           term == "(Intercept)",
           true = "Random Intercept",
           false = "Random Slope"
         )))
```

```{r ess-math-school-ranef, fig.cap = "Random effects for schools"}
# Plot random effect for schools nested within districts
ranef_school_f %>% 
  group_by(term) %>% 
  # Reorder group based on by conditional means for plotting
  mutate(qcaa_school_id = fct_reorder(qcaa_school_id, condval)) %>% 
  ggplot() +
  geom_point(aes(x = condval,
                 y = qcaa_school_id)) +
  geom_vline(xintercept = 0,
             size = 1,
             colour = "red") +
  facet_wrap(~ term,
             scales = "free_x")
```

As shown in the model output and in Figure \@ref(fig:ess-math-school-ranef), there was little correlation (-0.12) between the random intercept and slope. Schools with appear to decrease or increase in enrolments at different rates; This may be attributed to the fact that the data only consists of observations for three years and there is not enough data to evaluate the enrolment patterns in schools.

```{r ess-math-district-ranef, fig.cap = "Random intercept for districts"}
# Plot random effects for between districts
ranef_district_f %>% 
# Reorder group based on by conditional means
  mutate(qcaa_district = fct_reorder(qcaa_district, condval)) %>% 
  ggplot() + 
  geom_point(aes(x = condval,
                 y = qcaa_district)) +
  geom_vline(xintercept = 0,
             colour = "red",
             size = 1) +
  facet_wrap(~ term,
             scales = "free_x")
```

As the random slopes are removed, all districts are predicted to have the same increase in enrolments over the years; And as was discussed previously, this was a reasonable assumption or an otherwise perfect correlation with random slope and intercept will be fitted. Figure \@ref(fig:ess-math-district-ranef) demonstrates that schools in Gold Coast has the largest enrolments while Mackay have the lowest enrolments in Essential Mathematics subject, on average.

### Predictions

```{r ess-math-pred, fig.cap = "Model predictions for 20 randomly selected schools"}
# Predictions for 20 randomly selected schools for year 11 enrolments
set.seed(136)
ess_math_long %>% 
  filter(unit == "year_11_enrolments") %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, 20)) %>% 
  mutate(pred = predict(model_f, newdata = .)) %>% 
  ggplot() +
  geom_line(aes(x = completion_year,
                y = log(enrolments),
                group = qcaa_school_id)) +
  geom_line(aes(x = completion_year,
                y = pred,
                group = qcaa_school_id),
            colour = "orange") +
  facet_wrap(~ qcaa_school_id) +
  theme(axis.text.x = element_text(angle = 90))
```

Figure \@ref(fig:ess-math-pred) above shows the predictions for 20 randomly selected schools.

















