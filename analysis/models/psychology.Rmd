---
title: "Multilevel Model for Psychology"
author: "Brendi Ang"
date: "17/10/2021"
output: 
  bookdown::html_document2:
    theme: flatly
    toc: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(broom)
library(broom.mixed)
library(colorspace)
library(kableExtra)
library(lme4)
library(patchwork)

ggplot2::theme_set(theme_bw())

select <- dplyr::select
```

```{r, include=FALSE, warning=FALSE}
# Read-in data
mathsci_all <- read_csv(here::here("data/mathsci_all.csv"),
                        col_types = cols(doe_centre_code = col_factor()))

# Convert data types
mathsci_all <- mathsci_all %>% 
  mutate(across(.cols = c(qcaa_subject_id, 
                          subject_type,
                          qcaa_school_id,
                          sector,
                          school_postcode
                          ),
                ~ as.factor(.x))) 
```

```{r}
psych <- mathsci_all %>% 
  filter(subject_name == "Psychology")

psych_long <- psych %>% 
  pivot_longer(cols = year_11_enrolments:year_12_enrolments,
               names_to = "unit",
               values_to = "enrolments") 
```

# Psychology

## Getting the data ready for modelling

## Exploring the dataset with basic linear model for each school

```{r psych-eda, fig.cap = "Basic linear model for 20 randomly selected schools to provide an at-a-glance visualisation of enrolment trends within schools for Psychology"}

# Fit a linear model for 20 random sampled schools
set.seed(7367)

psych_long %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, size = 21),
         enrolments > 0) %>% 
  ggplot(aes(x = completion_year,
             y = enrolments)) +
  geom_point() +
  stat_smooth(method = "lm",
              colour = "orange") +
  facet_wrap(~ qcaa_school_id) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Completion year",
       y = "Enrolments",
       title = "Linear fit for 20 randomly selected schools")
```

As aforementioned, Psychology was one of the few subjects that were introduced in the new QCE system. As seen in Figure \@ref(fig:psych-ed), there were only observations for 3 consecutive years (up till cohort graduating in 2022). The linear fit indicates that the enrolment trends for these 20 randomly selected schools were rather constant. Schools differ in cohort size, for instance, schhool 264 and 161 have enrolments above 200 for a single cohort, whereas school 560 and 581 have less than 50 enrolments in a single cohort.

### Linearise response variable using log transformation

```{r}
p1 <- ggplot(psych_long, aes(enrolments)) +
      geom_histogram(binwidth = 15,
                     fill = "white",
                     colour = "black") +
      geom_density(aes(y = 15 * ..count..),
                   fill = "steelblue",
                   alpha = 0.4) +
    labs(title = "Before log transformation",
         x = "Enrolments",
         y = "Density")

p2 <- ggplot(psych_long, aes(log(enrolments))) +
      geom_histogram(binwidth = 0.3,
                     fill = "white",
                     colour = "black") +
      geom_density(aes(y= 0.3 * ..count..),
                   fill = "steelblue",
                   alpha = 0.4) +
  labs(title = "After log transformation",
       x = "Log Enrolments",
       y = "Density")

p1 / p2
```

The enrolments were right skewed, which is likely to be attributed to the various school sizes (as seen in Figure \@ref(fig:psych-eda)). A log transformation was implemented to the response variable (*i.e.* `enrolments`) to allow the the multilevel model to better capture the enrolment patterns. 

```{r}
# ----- Cleaning script

psych <- psych %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove schools that offer subject in one of Year 11 or Year 12 only
  filter(year_12_enrolments != 0,
         year_11_enrolments != 0)

psych_long <- psych_long %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove schools that offer subject in one of Year 11 or Year 12 only
  filter(enrolments != 0) %>% 
  # Recentre year
  mutate(year20 = completion_year - min(completion_year),
         .before = completion_year) %>% 
  # Log transformation of response variable
  mutate(log_enrolments = log(enrolments))
```

## Unconditional means model

```{r}
# ----- Fit possible null model

# Two-level: Within schools
model0.0 <- lmer(log_enrolments ~ 1 + (1 | qcaa_school_id),
                 data = psych_long)

# Three-level: Schools nested within postcodes
model0.1 <- lmer(log_enrolments ~ 1 + (1 | school_postcode/qcaa_school_id),
                 data = psych_long)

# Three-level Schools nested within districts
model0.2 <- lmer(log_enrolments ~ 1 + (1 | qcaa_district/qcaa_school_id),
                 data = psych_long)
```

```{r}
# Obtain AIC for each null model
model0_AIC <- AIC(model0.0, model0.1, model0.2) 

# Change row names 
rownames(model0_AIC) <- c("Model0.0: Within schools",
                          "Model0.1: Schools nested within postcodes",
                          "Model0.2: Schools nested within districts")

model0_AIC %>% 
  arrange(AIC) %>% 
  kable() %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = c("hovered", "striped"))
```

Referring back to [step 3](#step-three), three candidate models are fitted, with the AIC shown in Table \@ref(tab:psych-init-models). `Model0.2`, corresponding to having schools nested within districts is the best model, with optimised (lowest) AIC and will be used in the subsequent analysis.

### Intraclass correlation ($ICC$)

```{r, echo=TRUE,eval=FALSE}
summary(model)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model0.2)

cat("Random effects:", "\n")

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

cat("\n","Fixed effects:", "\n")
# Extract fixed effects coefficient
coef(summary(model0.2))

# Print grouping structure
cat("\n",
    "Number of schools (level-two group) =",
    summary(model0.2)$ngrps[1], "\n", 
    "Number of district (level-three group) =",
    summary(model0.2)$ngrps[2])
```

This model takes into account 169 schools nested in 13 districts. In a three-level multilevel model, two intraclass correlations can be obtained using the model summary output above:

The **level-two ICC** relates to the correlation between school $i$ from a certain district $k$ in time $t$ and in time $t^*$:

$$ \text{level-two ICC} = \frac{\tau^{2}_{00}}{\tau^{2}_{00} + \phi^{2}_{00} + \sigma^2} = \frac{0.48216}{(0.48216 + 0.09015 + 0.10038)} = 0.7168$$

This can be conceptualised as the correlation between enrolments of two random draws from the same school at two different years. In other words, 71.68% of the total variability is attributable to the differences between schools from the same district rather than changes over time within schools.

The **level-three ICC** refers to the correlation between different schools $i$ and $i^*$ from a specific school $j$. 

$$\text{level-two ICC} = \frac{\phi^2_{00}}{\tau^2_{00} + \phi^2_{00} + \sigma^2} = \frac{0.09015}{(0.48216 + 0.09015 + 0.10038)} = 0.1340$$

## Unconditional Growth model

```{r}
# Unconditional growth model
model1.0 <- lmer(log_enrolments ~ year20 + 
                (year20 | qcaa_district:qcaa_school_id) + 
                (year20 | qcaa_district),
                REML = TRUE,
                data = psych_long)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model1.0)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model1.0))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model1.0)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model1.0)$ngrps[2])
```

The unconditional growth model adds the systematic changes over time, the model specification can be found in [step 4](#step-four). This allows for assessing within-school variability which can be attributed to the linear changes over time. Based on the model output:

- $\pi_{0ij}$ = 3.6365: Initial status for school $i$ in district $j$ (*i.e.* expected log enrolments when time = 0)
- $\pi_{1ij}$ = 0.0848: Growth rate for school $i$ in district $j$
- $\epsilon_{tij}$ = 0.0568: Variance in within-school residuals after accounting for linear growth overtime

Psychology was introduced in 2020, and schools are expected to have 37.9587 ($e^{3.7837}$), on average. Furthermore, enrolments were expected to increase by 8.8499\% ($e^{0.0848} - 1) \times 100$) every year. The estimated within-school variance decrease by 43.3695\% (0.10038 to 0.0568457), implying that 43.3695\% of the within-school variability can be explained by the linear growth over time.


## Testing fixed effects

```{r}
model4.0 <- lmer(log_enrolments ~ year20*sector*unit +
                (year20 | qcaa_district:qcaa_school_id) + 
                (year20 | qcaa_district),
                REML = FALSE,
                control = lmerControl(optimizer = "bobyqa"),
                data = psych_long)

# ----- Specify all models with different fixed effects

# --- Remove three-way interaction

model4.1 <- update(model4.0, . ~ . - sector:unit:year20)

# --- Remove two two-way interaction

model4.2 <- update(model4.1, . ~. - sector:year20 - unit:year20)

model4.3 <- update(model4.1, . ~. - unit:sector - sector:year20)

model4.4 <- update(model4.1, . ~. - unit:sector - unit:year20)

# --- Remove one two-way interaction

# Remove sector:unit interaction
model4.5 <- update(model4.1, . ~ . - sector:unit)

# Remove sector:year20 interaction
model4.6 <- update(model4.1, . ~ . - sector:year20)

# Remove unit:year20 interaction
model4.7 <- update(model4.1, . ~ . - unit:year20)

# --- No interactions

# Include 3 fixed effects
model4.8 <- update(model4.1, . ~. - unit:year20 - sector:year20 - unit:year20)

# Remove unit fixed effects
model4.9 <- update(model4.8, . ~. - unit)

# Remove sector fixed effects
model4.10 <- update(model4.8, . ~. - sector)
```


```{r}
# ANOVA test
model_anova <- anova(
  model4.0,
  model4.1,
  model4.2,
  model4.3,
  model4.4,
  model4.5,
  model4.6,
  model4.7,
  model4.8,
  model4.9,
  model4.10
)


model_anova %>% 
  as_tibble() %>% 
  select(npar, AIC, BIC, logLik) %>% 
  mutate(model = rownames(model_anova),
         .before = npar) %>% 
  arrange(AIC)
```

As detailed in [step 6](#step-six), level-two predictors (`sector` and `unit`) are added to the model. The largest possible model will be fitted, before removing each fixed effect one by one whilst recording the AIC for each model. `model4.0` corresponds to the largest model while `model4.10` is the smallest possible model. The model with the optimal (lowest) AIC is the largest possible model `model4.6`, and will be used in subsequent sections.

## Parametric bootstrap to test random effects

```{r}
bootstrapAnova <- function(mA, m0, B = 1000){
  oneBootstrap <- function(m0, mA){
    
    # Regenerate new set of response with the null model
    d <- drop(simulate(m0))
    
    # Fit both null and full model to the new data
    m2 <- refit(mA, newresp=d)
    m1 <- refit(m0, newresp=d)
    
    # Return chisq test statistic
    return(anova(m2,m1)$Chisq[2])
  }  
  
  # Conduct test 1,000 times and
  # Store chisq test statistic for each iteration
  nulldist <- replicate(B, oneBootstrap(m0, mA))
  
  # chisq statistic based on the proposed and null model
  ret <- anova(mA, m0)
  
  # Change p-value to bootstrap p-value
  # Proportion of times simulated chisq statistic > actual chisq test statistic
  ret$"Pr(>Chisq)"[2] <- mean(ret$Chisq[2] < nulldist)
  
  # Change name from Pr(>Chisq) to Pr_boot(>Chisq)
  names(ret)[8] <- "Pr_boot(>Chisq)"
  
  # Change heading of model output
  attr(ret, "heading") <- c(attr(ret, "heading")[1], 
    paste("Parametric bootstrap with", B,"samples."),
    attr(ret, "heading")[-1])
  
  attr(ret, "nulldist") <- nulldist
  return(ret)
}
```


```{r}
# Best model based on AIC and BIC

# Proposed model
balt <- lmer(log_enrolments ~ year20 + sector + unit + + year20:unit + sector:unit +
               (year20 | qcaa_district:qcaa_school_id) +  
               (year20 | qcaa_district),
             REML = FALSE,
             data = psych_long)

# Null model
bnull <- lmer(log_enrolments ~ year20 + sector + unit + + year20:unit + sector:unit +
               (year20 | qcaa_district:qcaa_school_id) +  
               (1 | qcaa_district),
              REML = FALSE,
              data = psych_long)

actual <- 2*(logLik(balt) - logLik(bnull))
```

```{r, eval=FALSE, warning=FALSE, message=FALSE}
bootstrapLRT <- bootstrapAnova(mA = balt,
                               m0 = bnull, 
                               B = 1000)

save(bootstrapLRT, file = here::here("data/bootstrapLRT/psych.rda"))
```


```{r psych-bootstrapLRT-tab}
# Load bootstrap likelihood ratio test output
load(here::here("data/bootstrapLRT/psych.rda"))

as_tibble(bootstrapLRT) %>% 
  kable(caption = "Parametric Bootstrap to compare larger and smaller, nested model") %>% 
  kable_styling(full_width = FALSE)
```


```{r psych-bootstrapLRT-fig, fig.cap = "Histogram of likelihood ratio test statistic, with a red vertical line indicating the likelihood ratio test statistic for the actual model"}
nullLRT = attr(bootstrapLRT, "nulldist")
x = seq(0, max(nullLRT), length = 100)
y = dchisq(x, 2)

nullLRT.1 <- as.data.frame(cbind(nullLRT = nullLRT, x = x, y = y))

ggplot(nullLRT.1) +
  geom_histogram(
    aes(x = nullLRT, y = ..density..),
    bins = 25,
    color = "black",
    fill = "white"
  ) + 
  geom_vline(xintercept = actual, 
             size = 1,
             colour = "red") +
  geom_line(aes(x = x, y = y)) +
  # xlim(c(-.5,10)) +
  labs(y = "Density",
       x = "Likelihood Ratio Test Statistics from Null Distribution") 
```

The parametric bootstrap is used to approximate the likelihood ratio test statistic to produce a more accurate p-value by simulating data under the null hypothesis (detailed explanation can be found in [step 7](#step-seven). Figure \@ref(fig:psych-bootstrapLRT-fig) displays the likelihood ratio test statistic from the null distribution, with the red line indicates the likelihood ratio test statistic using the actual data. 

The p-value indicates the proportion of times in which the bootstrap test statistic is greater than the observed test statistic. The low estimated $p$-value is 0.829 < 0.05 (Table \@ref(tab:psych-bootstrapLRT-tab)) fails to reject the null hypothesis at the 5% level, indicating that the smaller model (excluding random slope at level three) is preferred.

## Confidence interval

```{r}
# Fit best model with restricted maximum likelihood estimates
model_f <- lmer(log_enrolments ~ year20 + sector + unit + + year20:unit + sector:unit +
               (year20 | qcaa_district:qcaa_school_id) +  
               (1 | qcaa_district),
              REML = TRUE,
              data = psych_long)
```

```{r, eval=FALSE}
confint_f <- confint(model_f,
        method = "boot",
        oldNames = FALSE)

save(confint_f, file = here::here("data/confint/psych.rda"))
```

```{r}
load(here::here("data/confint/psych.rda"))

as_tibble(confint_f) %>% 
  mutate(var = rownames(confint_f),
         .before = `2.5 %`) %>% 
  kable(caption = "95% confidence intervals for fixed and random effects in the final model") %>% 
  kable_styling(full_width = FALSE)
```

The parametric bootstrap is utilised to construct confidence intervals (detailed explanation in [step 8](#step-eight)) for the random effects. If the confidence intervals between the random effects does not include 0, it provides statistical evidence that the p-value is less than 0.5. In other words, it suggests that the random effects and the correlation between the random effects are significant at the 5% level. The confidence interval for the random effects all exclude 0, indicating that they're different from 0 in the population (*i.e.* statistically significant).

## Interpreting final model


### Composite model 

- Level one (measurement variable)
$$Y_{tij} = \pi_{0ij} + \pi_{1ij}year20_{tij} + \epsilon_{tij}$$

- Level two (schools within districts) 
  $$\pi_{0ij} = \beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + \beta_{03j}sector_{ij}unit_{ij} + u_{0ij} \\ 
    \pi_{1ij} = \beta_{10j} + \beta_{11j}unit{ij} + u_{1ij}$$

- Level three (districts)
  $$\beta_{00j} = \gamma_{000} + r_{00j} \\
    \beta_{01j} = \gamma_{010} + r_{01j} \\
    \beta_{02j} = \gamma_{020} + r_{02j} \\
    \beta_{03j} = \gamma_{030} + r_{03j} \\
    \beta_{10j} = \gamma_{100} \\
    \beta_{11j} = \gamma_{110} $$

Therefore, the composite model can be written as

$$\begin{aligned} 
Y_{tij} =\ &\pi_{0ij} + \pi_{1ij}year20_{tij} + \epsilon_{tij} \\

        =\ & (\beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + \beta_{03j}sector_{ij}unit_{ij} + u_{0ij}) + \\
          & (\beta_{10j} + \beta_{11j}unit{ij})year20_{tij} + \epsilon_{tij} \\
           
        =\ & \left[\gamma_{000} + r_{00j} + (\gamma_{010} + r_{01j})sector_{ij} + (\gamma_{020} + r_{02j})unit_{ij} + (\gamma_{030} +
                  r_{03j})sector_{ij}unit_{ij} + u_{0ij} \right] + \\
           & \left[\gamma_{100} + \gamma_{110}unit_{ij} + u_{1ij} \right]year20_{tij} + \epsilon_{tij} \\
              
        =\ & \left[\gamma_{000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{030}sector_{ij}unit_{ij} + \gamma_{100}year20_{tij} + \gamma_{110}unit_{ij}year20_{tij} \right] \\
           & \left[r_{00j} + r_{01j}sector_{ij} + r_{02j}unit_{ij} + r_{03j}sector_{ij}unit_{ij} + u_{0ij} + u_{1ij}year20_{tij} + \epsilon_{tij} \right]
            
\end{aligned}$$ 

### Fixed effects

```{r}
# Extract fixed effects for final model
fixef_f <- fixef(model_f)

# \gamma_{000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{030}sector_{ij}unit_{ij} + 
# \gamma_{100}year20_{tij} + \gamma_{110}unit_{ij}year20_{tij}

# Catholic (unit 11)
fit_cat_unit11 <- fixef_f[[1]] + fixef_f[[2]] * c(0:5) 

# Catholic (unit 12)
fit_cat_unit12 <-
  fixef_f[[1]] + fixef_f[[5]] + fixef_f[[2]] * c(0:5) + fixef_f[[6]] * c(0:5)

# Government (unit 11)
fit_gov_unit11 <-
  fixef_f[[1]] + fixef_f[[3]] + fixef_f[[2]] * c(0:5)

# Government (unit 12)
fit_gov_unit12 <-
  fixef_f[[1]] + fixef_f[[3]] + fixef_f[[5]] + fixef_f[[7]] + fixef_f[[2]] * c(0:5) + fixef_f[[6]] * c(0:5)
  
# Independent (unit 11)
fit_ind_unit11 <-
  fixef_f[[1]] + fixef_f[[4]] + fixef_f[[2]] * c(0:5)
  
# Independent (unit 12)
fit_ind_unit12 <-
  fixef_f[[1]] + fixef_f[[4]] + fixef_f[[5]] + fixef_f[[8]] + fixef_f[[2]] * c(0:5) + fixef_f[[6]] * c(0:5)
```

```{r}
fit_f <-
  tibble(
    # Unit 11
    Catholic_unit11 = fit_cat_unit11,
    Government_unit11 = fit_gov_unit11,
    Independent_unit11 = fit_ind_unit11,
    # Unit 12
    Catholic_unit12 = fit_cat_unit12,
    Government_unit12 = fit_gov_unit12,
    Independent_unit12 = fit_ind_unit12,
    # Time variables
    year92 = 0:5,
    completion_year = year92 + 2020
  )

# Convert to long form for plotting
fit_f <- fit_f %>% 
  pivot_longer(cols = Catholic_unit11:Independent_unit12,
               names_to = "sector_unit",
               values_to = "fit") 

fit_f <- fit_f %>% 
  # Separate sector and unit into two variables
  separate(sector_unit, 
           into = c("sector", "unit"), 
           sep = "_",
           remove = FALSE) # Keep old variable for grouping in plot
```

```{r, eval=FALSE, echo=TRUE}
summary(model_f)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model_f)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model_f))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model_f)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model_f)$ngrps[2])
```

```{r psych-fixef, fig.cap = "Fixed effects of the final model for Agricultural Practices subject"}
fit_f %>% 
  ggplot(aes(x = completion_year,
             y = fit,
             group = sector_unit,
             colour = sector)) +
  geom_line(aes(linetype = unit),
            size = 1,
            alpha = 0.7) +
  scale_colour_discrete_qualitative() +
  labs(title = "Fixed effects of final model",
       x = "Completion Year",
       y = "Predicted log enrolments") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 90)) +
  scale_x_continuous(breaks = seq(2020, 2025, by = 1),
                     labels = seq(2020, 2025, by = 1)) 
```

As the final model does not have a random slope at level 3, schools across sector are assumed to have the same slope in the fixed effects, but at different intercept (baseline). As seen in Figure \@ref(fig:psych-fixef), unit 12 are expected to be more than unit 11 in the later years, suggesting that students may be completing the year 11 syllabus in year 10, before re-enrolling in year 12. It appears that government schools are estimated to have the highest enrolment in Psychology, with independent schools having the least enrolments, on average.

### Random effects

```{r}
# Random effects for schools within districts
ranef_school_f <- as_tibble(ranef(model_f)) %>%
  filter(!grp %in% unique(mathsci_all$qcaa_district)) %>% 
  separate(
    col = grp,
    into = c("qcaa_district", "qcaa_school_id"),
    sep = ":",
    remove = FALSE
  ) %>% 
  # Rename intercept and slope names
  mutate(term = if_else(term == "(Intercept)",
                        true = "Random Intercept",
                        false = "Random Slope")) 

# Random effects for between districts
ranef_district_f <- as_tibble(ranef(model_f)) %>% 
  filter(grp %in% unique(mathsci_all$qcaa_district)) %>% 
  group_by(term) %>% 
  rename(qcaa_district = grp) %>% 
  # Rename intercept and slope names
  mutate(term =  as.character(term),
         term = factor(if_else(
           term == "(Intercept)",
           true = "Random Intercept",
           false = "Random Slope"
         )))
```

```{r}
# Plot random effect for schools nested within districts
ranef_school_f %>% 
  group_by(term) %>% 
  # Reorder group based on by conditional means for plotting
  mutate(qcaa_school_id = fct_reorder(qcaa_school_id, condval)) %>% 
  ggplot() +
  geom_point(aes(x = condval,
                 y = qcaa_school_id)) +
  geom_vline(xintercept = 0,
             size = 1,
             colour = "red") +
  facet_wrap(~ term,
             scales = "free_x")
```

As shown in the model output and in Figure \@ref(fig:psych-school-ranef), there was little correlation (-0.36) between the random intercept and slope. Schools with appear to decrease or increase in enrolments at different rates; This may be attributed to the fact that the data only consists of observations for three years and there is not enough data to evaluate the enrolment patterns in schools.

```{r psych-district-ranef, fig.cap = "Model predictions for 20 randomly selected schools"}
# Plot random effects for between districts
ranef_district_f %>% 
# Reorder group based on by conditional means
  mutate(qcaa_district = fct_reorder(qcaa_district, condval)) %>% 
  ggplot() + 
  geom_point(aes(x = condval,
                 y = qcaa_district)) +
  geom_vline(xintercept = 0,
             colour = "red",
             size = 1) +
  labs(title = "Intercept")
```

As the random slopes are removed, all districts are predicted to have the same increase in enrolments over the years; And as was discussed previously, this was a reasonable assumption or an otherwise perfect correlation with random slope and intercept will be fitted. Figure \@ref(fig:psych-district-ranef) demonstrates that schools in Brisbane Central has the largest enrolments while Brisbane South have the lowest enrolments in this subject, on average.

### Predictions

```{r psych-pred, fig.cap = "Model predictions for 20 randomly selected schools"}
# Predictions for 20 randomly selected schools for year 11 enrolments
set.seed(1782)

psych_long %>% 
  filter(unit == "year_11_enrolments") %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, 16)) %>% 
  mutate(pred = predict(model_f, newdata = .)) %>% 
  ggplot() +
  geom_line(aes(x = completion_year,
                y = log(enrolments),
                group = qcaa_school_id)) +
  geom_line(aes(x = completion_year,
                y = pred,
                group = qcaa_school_id),
            colour = "orange") +
  facet_wrap(~ qcaa_school_id) +
  theme(axis.text.x = element_text(angle = 90))
```

Figure \@ref(fig:psych-pred) above shows the predictions for 20 randomly selected schools.

