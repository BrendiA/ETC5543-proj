---
title: "Multilevel Model for Specialist Mathematics"
author: "Brendi Ang"
date: "17/10/2021"
header-includes: 
- \usepackage{float} 
- \floatplacement{figure}{H}
linestretch: 1.3
mainfont: Arial
output: 
  bookdown::pdf_document2:
    theme: flatly
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: yes 
    number_sections: false
---

```{r spec-math-setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  fig.pos = "H",
  fig.height = 7,
  fig.width = 9,
  fig.align = "center"
)

options(knitr.table.format = function() {
  if (knitr::is_latex_output())
    "latex" else "html"
})
```

```{r, include=FALSE}
library(tidyverse)
library(broom)
library(broom.mixed)
library(colorspace)
library(here)
library(kableExtra)
library(knitr)
library(lme4)
library(patchwork)

ggplot2::theme_set(theme_bw())

select <- dplyr::select
```

```{r, include=FALSE, warning=FALSE}
# Read-in data
mathsci_all <- read_csv(here::here("data/mathsci_all.csv"),
                        col_types = cols(doe_centre_code = col_factor()))

# Convert data types
mathsci_all <- mathsci_all %>% 
  mutate(across(.cols = c(qcaa_subject_id, 
                          subject_type,
                          qcaa_school_id,
                          sector,
                          school_postcode
                          ),
                ~ as.factor(.x))) 
```

# Specialist Mathematics

```{r}
# Specialist Mathematics subject 
spec_math <- mathsci_all %>%
  filter(subject_name == "Specialist Mathematics") 

# Convert to long format for modelling & plotting
spec_math_long <- spec_math %>% 
  pivot_longer(cols = year_11_enrolments:year_12_enrolments,
               names_to = "unit",
               values_to = "enrolments") 
```


## Exploring the dataset with basic linear model

```{r spec-math-eda, fig.cap="Basic linear model for 20 randomly selected schools to provide an at-a-glance visualisation of enrolment trends within schools for Specialist Mathematics subject"}
# Fit a linear model for 20 random sampled schools
set.seed(3142)
spec_math_long %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, size = 20),
         enrolments > 0) %>% 
  ggplot(aes(x = completion_year,
             y = enrolments)) +
  geom_point() +
  stat_smooth(method = "lm",
              colour = "orange") +
  facet_wrap(~ qcaa_school_id) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  theme(axis.text.x = element_text(angle = 90))
```

With reference to the [first step](#step-one), Figure \@ref(fig:spec-math-eda) fits a linear model for enrolments for a random sample of 20 schools. A myriad of patterns can be obtained from this. For instance, enrolments in school 2 (top left) appears to have significant larger increase in enrolments over the years the specialist mathematics have been introduced. Most schools showed relatively small enrolment numbers of less than 50, however school 2 and 175 showed rather large enrolment numbers for each cohort. It also demonstrates that each school can introduce (or end) specialist mathematics at different years -- *e.g.* School 591 only introduced the subject in 2016, and School 113 introduced the subject in 1995 and discontinued the subject in 2005.

## Getting the data ready for modelling

### Removing zero enrolments

All zero enrolments in a given year will be removed for modelling. As aforementioned, most of the zero enrolments in year 11 (refer to Figure \@ref(fig:year-11-enrolments-all)) were attributed to the 2007 prep year cohort while zero enrolments in year 12 relates to the first year in which a school introduces the subject. Other zero enrolments mostly relates to smaller schools with little to no enrolments in the subject for a given year. These zero enrolments will be removed for modelling purposes.

### Linearise response variable using log transformation

```{r spec-math-log-scale, fig.cap = "Effects of log transformation for response variable (enrolments) in Specialist Mathematics subject"}
p1 <- spec_math_long %>%
  ggplot(aes(x = enrolments)) +
  geom_histogram(binwidth = 15,
                 fill = "white",
                 colour = "black") +
  geom_density(aes(y = 15 * ..count..),
               fill = "steelblue",
               alpha = 0.4) +
  labs(title = "Before log transformation",
       x = "Enrolments",
       y = "Density")

p2 <- spec_math_long %>%
  ggplot(aes(log(enrolments))) +
  geom_histogram(binwidth = 0.3,
                 fill = "white",
                 colour = "black") +
  geom_density(aes(y = 0.3 * ..count..),
               fill = "steelblue",
               alpha = 0.4) +
  labs(title = "After log transformation",
       x = "Log Enrolments",
       y = "Density")

p1 / p2
```

As multilevel model assumes normality in the error terms, a log transformation is utilised to allow models to be estimated by the linear mixed models. The log transformation allows enrolment numbers to be approximately normally distributed (Figure \@ref(fig:spec-math-log-scale)).

```{r}
# --- Cleaning script

spec_math <- spec_math %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove zero enrolments
  filter(year_12_enrolments != 0,
         year_11_enrolments != 0)

spec_math_long <- spec_math_long %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove zero enrolments
  filter(enrolments != 0) %>% 
  # Recentre year
  mutate(year92 = completion_year - min(completion_year),
         .before = completion_year) %>% 
  # Log transformation of response variable
  mutate(log_enrolments = log(enrolments))
```

## Unconditional means model

```{r}
# ----- Fit possible null model

# Two-level: Within schools
model0.0 <- lmer(log_enrolments ~ 1 + (1 | qcaa_school_id),
                 data = spec_math_long)

# Three-level: Schools nested within postcodes
model0.1 <- lmer(log_enrolments ~ 1 + (1 | school_postcode/qcaa_school_id),
                 data = spec_math_long)

# Three-level Schools nested within districts
model0.2 <- lmer(log_enrolments ~ 1 + (1 | qcaa_district/qcaa_school_id),
                 data = spec_math_long)
```

```{r spec-math-init-models}
# Obtain AIC for each null model
model0_AIC <- AIC(model0.0, model0.1, model0.2) 

# Change row names 
rownames(model0_AIC) <- c("Model0.0: Within schools",
                          "Model0.1: Schools nested within postcodes",
                          "Model0.2: Schools nested within districts")

model0_AIC %>% 
  arrange(AIC) %>% 
  kable(caption = "AIC values for all candidate models for Specialist Mathematics",
        booktabs = TRUE,
        linesep = "") %>% 
  kable_styling(full_width = FALSE,
                latex_options = c("striped", "HOLD_position"),
                bootstrap_options = c("hovered", "striped"))
```

As per [step 3](#step-three), the three potential models are fitted, with the AIC shown in Table \@ref(tab:spec-math-init-models). Based on the AIC, `model0.2`, corresponding the schools nested within districts is the best model and will be used in the subsequent analysis. 

### Intraclass correlation ($ICC$)

```{r, eval=FALSE, echo=TRUE}
summary(model0.2)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model0.2)

cat("Random effects:", "\n")

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

cat("\n","Fixed effects:", "\n")
# Extract fixed effects coefficient
coef(summary(model0.2))

# Print grouping structure
cat("\n",
    "Number of schools (level-two group) =",
    summary(model0.2)$ngrps[1], "\n", 
    "Number of district (level-three group) =",
    summary(model0.2)$ngrps[2])
```

This model will takes into account 422 schools nested in 13 districts. In a three-level multilevel model, two intraclass correlations can be obtained using the model summary output above:

The **level-two ICC** relates to the correlation between school $i$ from district $k$ in time $t$ and in time $t^* \ne t$:

$$\text{Level-two ICC} = \frac{\tau^{2}_{00}}{\tau^{2}_{00} + \phi^{2}_{00} + \sigma^2} = \frac{0.4213}{(0.4213 + 0.1116 + 0.2772)} = 0.5201$$
  
This can be conceptualised as the correlation between enrolments of two random draws from the same school at two different years. In other words, 52.01% of the total variability is attributable to the changes overtime within schools.

The **level-three ICC** refers to the correlation between different schools $i$ and $i^*$ from a specific district $j$ in time $t$ and time $t^* \ne t$. 

$$\text{Level-three ICC} = \frac{\phi^2_{00}}{\tau^2_{00} + \phi^2_{00} + \sigma^2} = \frac{0.1116}{(0.4213 + 0.1116 + 0.2772)} = 0.1378$$

Similarly, this can be conceptualised as the correlation between enrolments of two randomly selected schools from the same district -- *i.e.* 11.70% of the total variability is due to the difference between districts.
  
## Unconditional growth model

```{r}
# Unconditional growth model
model1.0 <- lmer(log_enrolments ~ year92 + 
                (year92 | qcaa_district:qcaa_school_id) + 
                (year92 | qcaa_district),
                REML = TRUE,
                control = lmerControl(optimizer = "bobyqa"),
                data = spec_math_long)
```


The unconditional growth model introduces the time predictor at level one, the model specification can be found in [step 4](#step-four). This allows for assessing within-school variability which can be attributed to linear changes over time. Furthermore, variability in intercepts and slopes can be obtained to compare schools within the same districts, and schools from different districts.

```{r, eval=FALSE, echo=TRUE}
summary(model1.0)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model1.0)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model1.0))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model1.0)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model1.0)$ngrps[2])
```

- $\pi_{0ij}$ = 1.7969: Initial status for school $i$ in district $j$ (*i.e.* expected log enrolments when time = 0)
- $\pi_{1ij}$ = 0.0165: Growth rate for school $i$ in district $j$
- $\epsilon_{tij}$ = 0.2093: Variance in within-school residuals after accounting for linear growth overtime

When the subject was first introduced in 1992, schools were expected to have 6.0309 ($e^{1.7848}$) enrolments, on average. This enrolments were rather low as there were only a small fraction of schools that offered the subject in 1992 (as demonstrated in Figure \@ref(fig:participating-schools)). On average, enrolments were expected to increase by 1.6614\% ($(e^{0.0164778} - 1)\times100$) per year. The estimated within-schools variance decreased by 24.45\% (0.2772 to 0.2093), implying that 24.5\% of within-school variability can be explained by the linear growth over time.


## Dealing with boundary constraints

```{r}
# ---- Reasonable model reparameterisation
# Remove year92 at district level
# Implies that \phi^2_{10}$ = $\phi_{01} = 0
model1.1 <- lmer(log_enrolments ~ year92 + 
                (year92 | qcaa_district:qcaa_school_id) + 
                (1 | qcaa_district),
                REML = TRUE,
                control = lmerControl(optimizer = "bobyqa"),
                data = spec_math_long)
```

A singular fit is observed in the model as the correlation between the intercept and slope between districts are perfectly correlation (*i.e.* $\phi_{01}$ = 1). This may suggest that the model is overfitted -- *i.e.* the random effects structure is too complex to be supported by the data and may require some re-parameterisation. Naturally, the higher-order random effects (*e.g.* random slope of the third level (between district)) can be removed, especially where the variance and correlation terms are estimated on the boundaries (*add bookdown reference*).

```{r, eval=FALSE, echo=TRUE}
summary(model1.1)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model1.1)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model1.1))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model1.1)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model1.1)$ngrps[2])
```

To elaborate, two parameters were removed by setting variance components $\phi^2_{10}$ = $\phi_{01}$ equal to zero Which indirectly assumes that the growth rate for district $j$ to be fixed. As shown in the output above, this produced a more stable model and is free from any boundary constraints. As compared to the unconditional growth model (`model1.0`), the fixed effects remained rather similar. 

Level one and level two will be identical to the unconditional growth model (`model1.0`), however, the random slope for level 3 will be removed. This implies that the error assumption at level three now follows a univariate normal distribution where $r_{00j} \sim N(0, \phi_{00}^{2})$.

The new Level three (districts):
  $$\beta_{00j} = \gamma_{000} + r_{00j} \\
    \beta_{10j} = \gamma_{100} $$
    
And therefore composite model:
$$\begin{aligned} Y_{tij} &= \pi_{0ij} + \pi_{1ij}year92_{tij} + \epsilon_{tij} \\ &= (\beta_{00j} + u_{0ij}) + (beta_{10j} + u_{1ij})year92_{tij} +  \epsilon_{tij} \\ &= (\gamma_{000} + r_{00j} + u_{0ij}) + (\gamma_{100} + u_{1ij})year92_{tij} + \epsilon_{tij} \\ &= \left[\gamma_{000} + \gamma_{100}year92_{tij}  \right] + 
             \left[r_{00j} + u_{0ij} + u_{1ij}year92_{tij} + \epsilon_{tij} \right]
\end{aligned}$$


## Testing Fixed effects


```{r, warning=FALSE}
# Include all fixed predictors & set to MLE estimates
model4.0 <- lmer(log_enrolments ~ sector*unit*year92 + (year92 | qcaa_district:qcaa_school_id) + 
                (1 | qcaa_district), 
     data = spec_math_long,
     control = lmerControl(optimizer = "bobyqa"),
     REML = FALSE)

# ----- Specify all models with different fixed effects

# --- Remove three-way interaction

model4.1 <- update(model4.0, . ~ . - sector:unit:year92)

# --- Remove two two-way interaction

model4.2 <- update(model4.1, . ~. - sector:year92 - unit:year92)

model4.3 <- update(model4.1, . ~. - unit:sector - sector:year92)

model4.4 <- update(model4.1, . ~. - unit:sector - unit:year92)

# --- Remove one two-way interaction

# Remove sector:unit interaction
model4.5 <- update(model4.1, . ~ . - sector:unit)

# Remove sector:year92 interaction
model4.6 <- update(model4.1, . ~ . - sector:year92)

# Remove unit:year92 interaction
model4.7 <- update(model4.1, . ~ . - unit:year92)

# --- No interactions

# Include 3 fixed effects
model4.8 <- update(model4.1, . ~. - unit:year92 - sector:year92 - unit:year92)

# Remove unit fixed effects
model4.9 <- update(model4.8, . ~. - unit)

# Remove sector fixed effects
model4.10 <- update(model4.8, . ~. - sector)
```

```{r spec-math-test-fixef}
# anova() used to extract AIC, BIC, and log-likelihood
model_anova <- anova(
  model4.0,
  model4.1,
  model4.2,
  model4.3,
  model4.4,
  model4.5,
  model4.6,
  model4.7,
  model4.8,
  model4.9,
  model4.10
)

# Note: Chisq is wrong as models are not nested
 
model_anova %>% 
  as_tibble() %>% 
  select(AIC) %>% 
  mutate(model = rownames(model_anova),
         .before = AIC) %>% 
  arrange(AIC) %>% 
  kable(caption = "AIC for all possible models with different combinations of fixed effects",
        booktabs = TRUE,
        linesep = "") %>% 
  kable_styling(full_width = FALSE,
                latex_options = c("striped", "HOLD_position"),
                bootstrap_options = c("hovered", "striped"))
```

As highlighted in [step 6](#step-six), `sector` and `unit` will be added as predictors to the model. The largest possible model will be fitted, before removing fixed effects one by one while recording the AIC for each model. In this case, `model4.0` corresponds to the largest possible model while `model4.10` is the smallest possible model. The model with the optimal (lowest) AIC is `model4.4` (Table \@ref(tab:spec-math-test-fixef)). The next section will test the selected model's random effects to build the final model.

## Testing random effects with parametric bootstrpa

This step will not be undertaken, as the random slope will not be included at level three as a boundary constraint was found in the unconditional growth model, indicating that the model will be overfitted if random slopes were included at level three.

```{r, eval=FALSE}
# Best model based on AIC and BIC

# Proposed model
balt <- lmer(log_enrolments ~ sector + sector:year92 + unit + year92 + 
                   (year92 | qcaa_district:qcaa_school_id) + (1 | qcaa_district),
             REML = FALSE,
             control = lmerControl(optimizer = "Nelder_Mead"),
             data = spec_math_long)

# Null model
bnull <- lmer(log_enrolments ~ sector + sector:year92 + unit + year92 + 
                   (1 | qcaa_district:qcaa_school_id) + (1 | qcaa_district),
              REML = FALSE,
              control = lmerControl(optimizer = "Nelder_Mead"),
              data = spec_math_long)

actual <- 2*(logLik(balt) - logLik(bnull))
```

```{r, eval=FALSE}
bootstrapAnova <- function(mA, m0, B = 1000){
  oneBootstrap <- function(m0, mA){
    
    # Regenerate new set of response with the null model
    d <- drop(simulate(m0))
    
    # Fit both null and full model to the new data
    m2 <- refit(mA, newresp=d)
    m1 <- refit(m0, newresp=d)
    
    # Return chisq test statistic
    return(anova(m2,m1)$Chisq[2])
  }  
  
  # Conduct test 1,000 times and
  # Store chisq test statistic for each iteration
  nulldist <- replicate(B, oneBootstrap(m0, mA))
  
  # chisq statistic based on the proposed and null model
  ret <- anova(mA, m0)
  
  # Change p-value to bootstrap p-value
  # Proportion of times simulated chisq statistic > actual chisq test statistic
  ret$"Pr(>Chisq)"[2] <- mean(ret$Chisq[2] < nulldist)
  
  # Change name from Pr(>Chisq) to Pr_boot(>Chisq)
  names(ret)[8] <- "Pr_boot(>Chisq)"
  
  # Change heading of model output
  attr(ret, "heading") <- c(attr(ret, "heading")[1], 
    paste("Parametric bootstrap with", B,"samples."),
    attr(ret, "heading")[-1])
  
  attr(ret, "nulldist") <- nulldist
  return(ret)
}
```

```{r, eval=FALSE, warning=FALSE, message=FALSE}
bootstrapLRT <- bootstrapAnova(mA = balt,
                               m0 = bnull, 
                               B = 1000)

save(bootstrapLRT, file = here::here("data/bootstrapLRT/spec-math.rda"))
```

```{r}
load(here::here("data/bootstrapLRT/spec-math.rda"))

as_tibble(bootstrapLRT) %>% 
  kable(caption = "Parametric Bootstrap to compare larger and smaller, nested model",
        booktabs = TRUE,
        linesep = "") %>% 
  kable_styling(full_width = FALSE,
                latex_options = c("striped", "HOLD_position"),
                bootstrap_options = c("hovered", "striped"))
```

```{r spec-math-bootstrapLRT, eval=FALSE}
nullLRT = attr(bootstrapLRT, "nulldist")
x = seq(0, max(nullLRT), length = 100)
y = dchisq(x, 2)

nullLRT.1 <- as.data.frame(cbind(nullLRT = nullLRT, x = x, y = y))

ggplot(nullLRT.1) +
  geom_histogram(
    aes(x = nullLRT, y = ..density..),
    bins = 25,
    color = "black",
    fill = "white"
  ) + 
  # geom_vline(xintercept = 1000, size = 1) +
  geom_line(aes(x = x, y = y)) +
  labs(title = "Likelihood ratio test statistic from null distribution, overlaid by the chi-square dsitribution",
       y = "Density",
       x = "Likelihood Ratio Test Statistics from Null Distribution") 
```

  
## Confidence interval

```{r}
# Re-fit best model with restricted maximum likelihood
model_f <- lmer(log_enrolments ~ sector + sector:year92 + unit + year92 +
                  (year92 | qcaa_district:qcaa_school_id) + (1 | qcaa_district),
             REML = TRUE,
             control = lmerControl(optimizer = "bobyqa"),
             data = spec_math_long)
```

```{r, eval=FALSE}
confint_f <- confint(model_f,
                     method = "boot",
                     oldNames = FALSE)

save(confint_f, file = here::here("data/confint/spec-math.rda"))
```

```{r spec-math-confint}
load(here::here("data/confint/spec-math.rda"))

as_tibble(confint_f) %>% 
  mutate(var = rownames(confint_f),
         .before = `2.5 %`) %>% 
  kable(caption = "95% confidence intervals for fixed and random effects in the final model",
        booktabs = TRUE,
        linesep = "",
        format = "pandoc") %>% 
  kable_styling(full_width = FALSE,
                latex_options = c("striped", "HOLD_position"),
                bootstrap_options = c("hovered", "striped"))
```


The parametric bootstrap is utilised to construct confidence intervals (detailed explanation in [step 8](#step-eight)) for the random effects. If the confidence intervals between the random effects does not include 0, it provides statistical evidence that the p-value is less than 0.5. In other words, it suggests that the random effects and the correlation between the random effects are significant at the 5% level. The confidence interval for the fixed and random effects all exclude 0 (Table \@ref(tab:spec-math-confint)), indicating that they're different from 0 in the population (*i.e.* statistically significant).

## Interpreting the final model

### Composite model

- Level one (measurement variable)
$$Y_{tij} = \pi_{0ij} + \pi_{1ij}year92_{tij} + \epsilon_{tij}$$

- Level two (schools within districts) 
$$\begin{aligned} \pi_{0ij} &= \beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + u_{0ij} \\ \pi_{1ij} &= \beta_{10j} + \beta_{11j}sector_{ij} + u_{1ij} \end{aligned}$$
    
- Level three (districts)
$$\begin{aligned}\beta_{00j} &= \gamma_{000} + r_{00j} \\ \beta_{01j} &= \gamma_{010} + r_{01j} \\ \beta_{02j} &= \gamma_{020} + r_{02j} \\
\beta_{10j} &= \gamma_{100} \\ \beta_{11j} &= \gamma_{110} \end{aligned}$$

Therefore, the composite model can be written as
$$\begin{aligned} Y_{tij} &= \pi_{0ij} + \pi_{1ij}year92_{tij} + \epsilon_{tij} \\ &= (\beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + u_{0ij}) + (\beta_{10j} + \beta_{11j}sector_{ij} + u_{1ij})year92_{tij} + \epsilon_{tij} \\ &= \left[\gamma_{000} + r_{00j} + (\gamma_{010} + r_{01j})sector_{ij} + (\gamma_{020} + r_{02j})unit_{ij} + u_{0ij} \right] + \left[\gamma_{100} + \gamma_{110}sector_{ij} + u_{1ij} \right]year92_{tij} + \epsilon_{tij} \\ &= \left[\gamma_{000} + \gamma_{010}sector_ {ij} + \gamma_{020}unit_{ij} + \gamma_{100}year92_{tij} + \gamma_{110}sector_{ij}year92_{tij} \right] + 
     \left[r_{00j} + r_{01j}sector_{ij} + r_{02j}unit_{ij} + u_{0ij} + u_{1ij}year92_{tij} + + \epsilon_{tij} \right]\end{aligned}$$
     

### Fixed effects

```{r}
# Extract fixed effects for model with unit and sector as predictors
fixef_f <- fixef(model_f)

# \gamma_{000} + \gamma_{010}sector_ {ij} + \gamma_{020}unit_{ij} + \gamma_{100}year92_{tij} + 
# \gamma_{110}sector_{ij}year92_{tij}   

# Catholic (unit 11)
fit_cat_unit11 <- fixef_f[[1]] + fixef_f[[5]] * c(0:30)

# Catholic (unit 12)
fit_cat_unit12 <- fixef_f[[1]] + fixef_f[[4]] + fixef_f[[5]] * c(0:30)
  
# Government (unit 11)
fit_gov_unit11 <- fixef_f[[1]] + fixef_f[[2]] + fixef_f[[5]] * c(0:30) + fixef_f[[6]] * c(0:30)


# Government (unit 12)
fit_gov_unit12 <- fixef_f[[1]] + fixef_f[[2]] + fixef_f[[4]] + fixef_f[[5]] * c(0:30) + fixef_f[[6]] * c(0:30)
  
# Independent (unit 11)
fit_ind_unit11 <- fixef_f[[1]] + fixef_f[[3]] + fixef_f[[5]] * c(0:30) + fixef_f[[7]] * c(0:30)
  
# Independent (unit 12)
fit_ind_unit12 <- fixef_f[[1]] + fixef_f[[3]] + fixef_f[[4]] + fixef_f[[5]] * c(0:30) + fixef_f[[7]] * c(0:30)
```

```{r}
# Save fixed effects into a data frame
fit_f <-
  tibble(
    # Unit 11
    Catholic_unit11 = fit_cat_unit11,
    Government_unit11 = fit_gov_unit11,
    Independent_unit11 = fit_ind_unit11,
    # Unit 12
    Catholic_unit12 = fit_cat_unit12,
    Government_unit12 = fit_gov_unit12,
    Independent_unit12 = fit_ind_unit12,
    # Time variables
    year92 = 0:30,
    completion_year = year92 + 1992
  )

# Convert to long format for plotting
fit_f <- fit_f %>% 
  pivot_longer(cols = Catholic_unit11:Independent_unit12,
               names_to = "sector_unit",
               values_to = "fit") 

# Separate sector and unit into two variables
fit_f <- fit_f %>% 
  separate(sector_unit, 
           into = c("sector", "unit"), 
           sep = "_",
           remove = FALSE) # Keep old variable for grouping in plot
```

```{r, eval=FALSE, echo=TRUE}
summary(model_f)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model_f)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model_f))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model_f)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model_f)$ngrps[2])
```

Based on the model output (see detailed explanation of fixed effects in [step 9](#step-nine)), the estimated mean enrolments for government schools are estimated to be 2.06% ($(e^{0.02044} - 1) \times 100$) more than that of catholic schools when the subject is first introduced in 1992 (*i.e.* larger initial status). Government schools are estimated to have a mean increase in enrolments of 1.2610% ($(e^{(0.01448 - 0.0019)} - 1) \times 100$) per year, which is -0.1948% ($(e^(-0.00194999) - 1) * 100)$) less than that of catholic schools.

On the other hand, independent schools have an estimated mean enrolments of 38% less than that of catholic schools when the subject is first introduced in 1992. However, this low initially low enrolments is matched with an a mean increase of 3.3976% per year, which is 1.9110% more than that of catholic schools per year.

```{r spec-math-fixef, fig.cap = "Fixed effects of the final model for Specialist Mathematics subject"}
fit_f %>% 
  ggplot(aes(x = completion_year,
             y = fit,
             group = sector_unit,
             colour = sector)) +
  geom_line(aes(linetype = unit),
            size = 1,
            alpha = 0.7) +
  scale_colour_discrete_qualitative() +
  labs(title = "Fixed effects of final model",
       x = "Completion Year",
       y = "Predicted log enrolments") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 90)) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  scale_y_continuous(limits = c(1.4, 2.4)) 
```

Based on the fixed effects, independent schools are expected to have highest log enrolments after 2020 (Figure \@ref(fig:spec-math-fixef). In all sectors, unit 11 enrolments appears to be marginally larger than unit 12, which may imply that students are taking the subject in year 10, so lesser students are enrolled in the subject in year 11. Government sectors appears to have the highest enrolment numbers initially (in year 1992), but have increases at a relatively slower rate as compared to the other sectors.

To be noted, these fixed effects considers all schools within the different sectors; Therefore, the many small government schools with little enrolments in the subject (as seen in Figure \@ref(fig:time-plot-all)) may 'down weight' the mean fixed effects of all schools.

### Random effects

```{r}
ranef_school_f <- as_tibble(ranef(model_f)) %>%
  # Random effects for schools within districts
  filter(!grp %in% unique(spec_math$qcaa_district)) %>% 
  separate(
    col = grp,
    into = c("qcaa_district", "qcaa_school_id"),
    sep = ":",
    remove = FALSE
  ) %>% 
  group_by(term) %>% 
  # Reorder group based on by conditional means
  mutate(qcaa_school_id = fct_reorder(qcaa_school_id, condval)) %>% 
  # Rename intercept and slope names
  mutate(term = if_else(term == "(Intercept)",
                        true = "Random Intercept",
                        false = "Random Slope")) 

# Random effects for between districts
ranef_district_f <- as_tibble(ranef(model_f)) %>% 
  filter(grp %in% unique(spec_math$qcaa_district)) %>% 
  group_by(term) %>% 
  rename(qcaa_district = grp) %>% 
  # Reorder group based on by conditional means
  mutate(qcaa_district = fct_reorder(qcaa_district, condval)) %>% 
  # Rename intercept and slope names
  mutate(term =  as.character(term),
         term = factor(if_else(
           term == "(Intercept)",
           true = "Random Intercept",
           false = term
         )))
```

```{r spec-math-school-ranef, fig.cap = "Random effects for all schools"}
# Plot random effect for schools nested within districts
ggplot(ranef_school_f) +
  geom_point(aes(x = condval,
                 y = qcaa_school_id),
             colour = "grey30",
             alpha = 0.8) +
  geom_vline(xintercept = 0,
             size = 1,
             colour = "red") +
  facet_wrap(~ term,
             scales = "free_x")
```

Figure \@ref(fig:spec-math-school-ranef) represents the random intercept and slope of the random effects for a given school. It is a manifest that the intercept and slope are negatively correlated, where a large intercept is associated with a smaller random slope. This suggests that a larger school is associated with a smaller increase (decrease) in enrolments over the years while smaller schools are predicted to have large increase in enrolments over the years.

```{r spec-math-distrcit-ranef, fig.cap = "Random intercept for districts"}
# Plot random effects for between districts
ggplot(ranef_district_f) + 
  geom_point(aes(x = condval,
                 y = qcaa_district)) +
  geom_vline(xintercept = 0,
             colour = "red",
             size = 1) +
  labs(title = "Random intercept for districts at level three")
```

As the random slopes are removed, all districts are predicted to have the same increase in enrolments over the years; And as was discussed previously, this was a reasonable assumption or an otherwise perfect correlation with random slope and intercept will be fitted. Figure \@ref(fig:spec-math-distrcit-ranef) demonstrates that schools in Brisbane Central has the largest enrolments, on average.


### Predictions

```{r spec-math-pred, fig.cap = "Model predictions for 20 randomly selected schools"}
set.seed(136)
# Predictions for 20 random schools
spec_math_long %>% 
  filter(unit == "year_11_enrolments") %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, 20)) %>% 
  # Exponentiate predictions to back transform to original scale
  mutate(pred = predict(model_f, newdata = .)) %>% 
  ggplot() +
  # Actual data
  geom_line(aes(x = completion_year,
                y = log_enrolments,
                group = qcaa_school_id)) +
  # Predicitons
  geom_line(aes(x = completion_year,
                y = pred,
                group = qcaa_school_id),
            colour = "orange") +
  facet_wrap(~ qcaa_school_id)
```

Figure \@ref(fig:spec-math-pred) above shows the predictions for 20 randomly selected schools.




















