---
title: "Multilevel Model for Agricultural Sciences"
author: "Brendi Ang"
date: "17/10/2021"
output: 
  bookdown::html_document2:
    theme: flatly
    toc: true
    number_sections: false
---

```{r agri-sci-setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(broom)
library(broom.mixed)
library(colorspace)
library(kableExtra)
library(lme4)
library(patchwork)

ggplot2::theme_set(theme_bw())

select <- dplyr::select
```

```{r, include=FALSE, warning=FALSE}
# Read-in data
mathsci_all <- read_csv(here::here("data/mathsci_all.csv"),
                        col_types = cols(doe_centre_code = col_factor()))

# Convert data types
mathsci_all <- mathsci_all %>% 
  mutate(across(.cols = c(qcaa_subject_id, 
                          subject_type,
                          qcaa_school_id,
                          sector,
                          school_postcode
                          ),
                ~ as.factor(.x))) 
``` 

# Agricultural Science

```{r}
agri_sci <- mathsci_all %>% 
  filter(subject_name == "Agricultural Science")

agri_sci_long <- agri_sci %>% 
  pivot_longer(cols = year_11_enrolments:year_12_enrolments,
               names_to = "unit",
               values_to = "enrolments") 
```

## Exploring the dataset with basic linear model

```{r agri-sci-eda, fig.cap="Basic linear model for 20 randomly selected schools to provide an at-a-glance visualisation of enrolment trends within schools for Agricultural Science subject", message=FALSE}
# Fit a linear model for 20 random sampled schools
set.seed(3120)

agri_sci_long %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, size = 23),
         enrolments > 0) %>% 
  ggplot(aes(x = completion_year,
             y = enrolments)) +
  geom_point() +
  stat_smooth(method = "lm",
              colour = "orange") +
  facet_wrap(~ qcaa_school_id) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(x = "Completion year",
       y = "Enrolments",
       title = "Linear fit for 20 randomly selected schools")
```

Figure \@ref(fig:agri-sci-eda) fits a linear model for 20 randomly selected schools. In most of these selected schools, the linear model captured a downward trend in enrolments. Some schools showed a increase, and in particular, school 288 showed a significant increase in enrolments as compared to the other selected schools. It seems that most schools that ceased offering the subject in the later years (*e.g.* schools 365, 490, 567) showed a large downward trend before ceasing the subject. Interestingly, school 508 displayed a rather cubic trend, where enrolments increases exponentially from 2002 before decrease till 2015 and picking up again.

## Getting the data ready for modelling

### Removing zero enrolments

All zero enrolments in a given year will be removed for modelling. As aforementioned, most of the zero enrolments in year 11 (refer to Figure \@ref(fig:year-11-enrolments-all)) were attributed to the 2007 prep year cohort while zero enrolments in year 12 relates to the first year in which a school introduces the subject. Other zero enrolments mostly relates to smaller schools with little to no enrolments in the subject for a given year. These zero enrolments will be removed for modelling purposes.

### Linearise response variable using log transformation

```{r agri-sci-log-scale, fig.cap = "Effects of log transformation for response variable (enrolments) in Agricultural Science subject", warning=FALSE}
p1 <- agri_sci_long %>%
  ggplot(aes(x = enrolments)) +
  geom_histogram(binwidth = 15,
                 fill = "white",
                 colour = "black") +
  geom_density(aes(y = 15 * ..count..),
               fill = "steelblue",
               alpha = 0.4) +
  labs(title = "Before log transformation",
       x = "Enrolments",
       y = "Density")

p2 <- agri_sci_long %>%
  ggplot(aes(log(enrolments))) +
  geom_histogram(binwidth = 0.3,
                 fill = "white",
                 colour = "black") +
  geom_density(aes(y = 0.3 * ..count..),
               fill = "steelblue",
               alpha = 0.4) +
  labs(title = "After log transformation",
       x = "Log Enrolments",
       y = "Density")

p1 / p2
```

The enrolments were right skewed, which is likely to be attributed to the various school sizes (as seen in Figure \@ref(fig:agri-sci-log-scale)). A log transformation was implemented to the response variable (*i.e.* `enrolments`) to allow the the multilevel model to better capture the enrolment patterns. 

```{r}
# ----- Cleaning script
agri_sci <- agri_sci %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove zero enrolments
  filter(year_12_enrolments != 0,
         year_11_enrolments != 0)

agri_sci_long <- agri_sci_long %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove zero enrolments
  filter(enrolments != 0) %>% 
  # Recentre year
  mutate(year94 = completion_year - min(completion_year),
         .before = completion_year) %>% 
  # Log transformation of response variable
  mutate(log_enrolments = log(enrolments))
```

## Unconditional means model

```{r}
# ----- Fit possible null model

# Two-level: Within schools
model0.0 <- lmer(log_enrolments ~ 1 + (1 | qcaa_school_id),
                 data = agri_sci_long)

# Three-level: Schools nested within postcodes
model0.1 <- lmer(log_enrolments ~ 1 + (1 | school_postcode/qcaa_school_id),
                 data = agri_sci_long)

# Three-level Schools nested within districts
model0.2 <- lmer(log_enrolments ~ 1 + (1 | qcaa_district/qcaa_school_id),
                 data = agri_sci_long)
```

```{r agri-sci-init-models}
# Obtain AIC for each null model
model0_AIC <- AIC(model0.0, model0.1, model0.2) 

# Change row names 
rownames(model0_AIC) <- c("Model0.0: Within schools",
                          "Model0.1: Schools nested within postcodes",
                          "Model0.2: Schools nested within districts")

model0_AIC %>% 
  arrange(AIC) %>% 
  kable(caption = "AIC values for all candidate models for Agricultural Science") %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = c("hovered", "striped"))
```

As outlined in [step 3](#step-three), the three candidate models are fitted and their AIC is shown in Table \@ref(tab:agri-sci-init-models). Based on the AIC, the two-level model (`model0.1`) corresponding to schools nested within postcodes is the superior model and will be used in the subsequent analysis.

### Intraclass correlation ($ICC$)

```{r, eval=FALSE, echo=TRUE}
summary(model0.1)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model0.1)

cat("Random effects:", "\n")

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

cat("\n","Fixed effects:", "\n")
# Extract fixed effects coefficient
coef(summary(model0.1))

# Print grouping structure
cat("\n",
    "Number of schools (level-two group) =",
    summary(model0.1)$ngrps[1], "\n", 
    "Number of school postcodes (level-three group) =",
    summary(model0.1)$ngrps[2])
```

This model will takes into account 112 schools nested in 81 postcodes. In a three-level multilevel model, two intraclass correlations can be obtained using the model summary output above:

The **level-two ICC** relates to the correlation between school $i$ from a certain postcode $k$ in time $t$ and in time $t^* \ne t$:

$$\text{Level-two ICC} = \frac{\tau^{2}_{00}}{\tau^{2}_{00} + \phi^{2}_{00} + \sigma^2} = \frac{0.4052}{(0.4052 + 0.1228 + 0.2918)} = 0.4943$$

This can be conceptualised as the correlation between enrolments of two random draws from the same school at two different years. In other words, 49.45% of the total variability is attributable to the changes over time within schools.

The **level-three ICC** refers to the correlation between different schools $i$ and $i^*$ from a specific postcode $j$. 

$$\text{Level-three ICC} = \frac{\phi^2_{00}}{\tau^2_{00} + \phi^2_{00} + \sigma^2} = \frac{0.1228}{(0.4052 + 0.1228 + 0.2918)} = 0.1498$$

Likewise, this can be loosely translated to be the correlation between enrolments of two random draws from two schools from two different postcode. In this case, 14.98% of the total variability is due to the difference between postcodes.

## Unconditional growth model

```{r}
# Unconditional growth model
model1.0 <- lmer(log_enrolments ~ year94 + 
                (year94 | school_postcode:qcaa_school_id) + 
                (year94 | school_postcode),
                REML = TRUE,
                control = lmerControl(optimizer = "bobyqa"),
                data = agri_sci_long)
```

The unconditional growth model introduces the time predictor at level one, the model specification can be found in [step 4](#step-four). This allows for assessing within-school variability which can be attributed to linear changes over time. Furthermore, variability in intercepts and slopes can be obtained to compare schools within the same postcodes, and schools from different postcodes.

```{r, eval=FALSE, echo=TRUE}
summary(model1.0)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model1.0)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model1.0))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model1.0)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model1.0)$ngrps[2])
```

- $\pi_{0ij}$ = 1.8388: Initial status for school $i$ in postcode $j$ (*i.e.* expected log enrolments when time = 0)
- $\pi_{1ij}$ = 0.0123: Growth rate for school $i$ in postcode $j$
- $\epsilon_{tij}$ = 0.2540: Variance in within-school residuals after accounting for linear growth overtime

When the subject was first introduced in 1994, schools were expected to have 6.2888 ($e^{1.8388}$) enrolments, on average. As displayed in Figure \@ref(fig:mean-enrolments-all), the average enrolments for agricultural science is relatively low, where the enrolments during the old QCE system had approximately 10 enrolments while the new QCE system had roughly 15 enrolments per school, on average. 

Enrolments were expected to increase by 1.2349\% ($(e^{0.01227} - 1)\times100$) per year. The estimated within-schools variance decreased by 12.968\% (0.2918 to 0.2539595), implying that 12.968\% of within-school variability can be explained by the linear growth over time.

## Testing fixed effects

```{r warning=FALSE}
model4.0 <- lmer(log_enrolments ~ year94*sector*unit +
                (year94 | school_postcode:qcaa_school_id) + 
                (year94 | school_postcode),
                REML = FALSE,
                data = agri_sci_long)

# ----- Specify all models with different fixed effects

# --- Remove three-way interaction

model4.1 <- update(model4.0, . ~ . - sector:unit:year94)

# --- Remove two two-way interaction

model4.2 <- update(model4.1, . ~. - sector:year94 - unit:year94)

model4.3 <- update(model4.1, . ~. - unit:sector - sector:year94)

model4.4 <- update(model4.1, . ~. - unit:sector - unit:year94)

# --- Remove one two-way interaction

# Remove sector:unit interaction
model4.5 <- update(model4.1, . ~ . - sector:unit)

# Remove sector:year94 interaction
model4.6 <- update(model4.1, . ~ . - sector:year94)

# Remove unit:year94 interaction
model4.7 <- update(model4.1, . ~ . - unit:year94)

# --- No interactions

# Include 3 fixed effects
model4.8 <- update(model4.1, . ~. - unit:year94 - sector:year94 - unit:year94)

# Remove unit fixed effects
model4.9 <- update(model4.8, . ~. - unit)

# Remove sector fixed effects
model4.10 <- update(model4.8, . ~. - sector)
```

```{r}
# ANOVA test
model_anova <- anova(
  model4.0,
  model4.1,
  model4.2,
  model4.3,
  model4.4,
  model4.5,
  model4.6,
  model4.7,
  model4.8,
  model4.9,
  model4.10
)


model_anova %>% 
  as_tibble() %>% 
  select(npar, AIC, BIC, logLik) %>% 
  mutate(model = rownames(model_anova),
         .before = npar) %>% 
  arrange(AIC)
```

- The AIC and BIC favoured `model4.3`.

## Parametric bootstrap to test random effects

```{r warning=FALSE}
bootstrapAnova <- function(mA, m0, B = 1000){
  oneBootstrap <- function(m0, mA){
    
    # Regenerate new set of response with the null model
    d <- drop(simulate(m0))
    
    # Fit both null and full model to the new data
    m2 <- refit(mA, newresp=d)
    m1 <- refit(m0, newresp=d)
    
    # Return chisq test statistic
    return(anova(m2,m1)$Chisq[2])
  }  
  
  # Conduct test 1,000 times and
  # Store chisq test statistic for each iteration
  nulldist <- replicate(B, oneBootstrap(m0, mA))
  
  # chisq statistic based on the proposed and null model
  ret <- anova(mA, m0)
  
  # Change p-value to bootstrap p-value
  # Proportion of times simulated chisq statistic > actual chisq test statistic
  ret$"Pr(>Chisq)"[2] <- mean(ret$Chisq[2] < nulldist)
  
  # Change name from Pr(>Chisq) to Pr_boot(>Chisq)
  names(ret)[8] <- "Pr_boot(>Chisq)"
  
  # Change heading of model output
  attr(ret, "heading") <- c(attr(ret, "heading")[1], 
    paste("Parametric bootstrap with", B,"samples."),
    attr(ret, "heading")[-1])
  
  attr(ret, "nulldist") <- nulldist
  return(ret)
}
```

```{r warning=FALSE}
# Best model based on AIC and BIC

# Proposed model
balt <- lmer(log_enrolments ~ year94 + sector + unit + year94:unit + 
               (year94 | school_postcode:qcaa_school_id) +      
               (year94 | school_postcode),
             REML = FALSE,
             data = agri_sci_long)

# Null model
bnull <- lmer(log_enrolments ~ year94 + sector + unit + year94:unit + 
               (year94 | school_postcode:qcaa_school_id) +      
               (1 | school_postcode),
              REML = FALSE,
              data = agri_sci_long)

# Actual likelihood ratio test statistic
actual <- 2*(logLik(balt) - logLik(bnull))
```

```{r, eval=FALSE, warning=FALSE, message=FALSE}
bootstrapLRT <- bootstrapAnova(mA = balt,
                               m0 = bnull, 
                               B = 1000)

save(bootstrapLRT, file = here::here("data/bootstrapLRT/agri-sci.rda"))
```

```{r agri-sci-bootstrapLRT-tab}
load(here::here("data/bootstrapLRT/agri-sci.rda"))

as_tibble(bootstrapLRT) %>% 
  kable(caption = "Parametric Bootstrap to compare larger and smaller, nested model") %>% 
  kable_styling(full_width = FALSE)
```

```{r agri-sci-bootstrapLRT-plot, fig.cap = "Histogram of likelihood ratio test statistic, with a red vertical line indicating the likelihood ratio test statistic for the actual model"}
nullLRT = attr(bootstrapLRT, "nulldist")
x = seq(0, max(nullLRT), length = 100)
y = dchisq(x, 2)

nullLRT.1 <- as.data.frame(cbind(nullLRT = nullLRT, x = x, y = y))

ggplot(nullLRT.1) +
  geom_histogram(
    aes(x = nullLRT, y = ..density..),
    bins = 25,
    color = "black",
    fill = "white"
  ) + 
  # geom_vline(xintercept = 1000, size = 1) +
  geom_line(aes(x = x, y = y)) +
  geom_vline(xintercept = actual,
             size = 1,
             colour = "red") +
  # xlim(c(-.5,10)) +
  labs(y = "Density",
       x = "Likelihood Ratio Test Statistics from Null Distribution") 
```

The parametric bootstrap is used to approximate the likelihood ratio test statistic to produce a more accurate p-value by simulating data under the null hypothesis (detailed explanation can be found in [step 7](#step-seven). Figure \@ref(fig:agri-sci-bootstrapLRT-plot) displays the likelihood ratio test statistic from the null distribution, with the red line indicates the likelihood ratio test statistic using the actual data. 

The p-value of 0.718\%  (Table \@ref(tab:agri-sci-bootstrapLRT-tab)) indicates the proportion of times in which the bootstrap test statistic is greater than the observed test statistic. The large estimated $p$-value is 0.718 < 0.05 fails to reject the null hypothesis at the 5% level, indicating that the smaller model (without random slope at level three) is preferred.

## Confidence interval

```{r}
model_f <-
  lmer(
    log_enrolments ~ year94 + sector + unit + year94:unit +
      (year94 | school_postcode:qcaa_school_id) +
      (1 | school_postcode),
    REML = TRUE,
    control = lmerControl(optimizer = "bobyqa"),
    data = agri_sci_long
  )
```

```{r, eval=FALSE}
confint_f <- confint(model_f,
        method = "boot",
        oldNames = FALSE)

save(confint_f, file = here::here("data/confint/agri-sci.rda"))
```

```{r}
load(here::here("data/confint/agri-sci.rda"))

as_tibble(confint_f) %>% 
  mutate(var = rownames(confint_f),
         .before = `2.5 %`) %>% 
  kable(caption = "95% confidence intervals for fixed and random effects in the final model") %>% 
  kable_styling(full_width = FALSE)
```

The parametric bootstrap is utilised to construct confidence intervals (as detailed in [step 8](#step-eight)). If the confidence intervals for the random effects does not include 0, it provides statistical evidence that the p-value is less than 0.5. In other words, it suggests that the random effects and the correlation between the random effects are significant at the 5% level. 

The 95% confidence interval is shown above, and the random effects all exclude 0, further reiterating that they are statistically significant at the 5% level. Some fixed effects such as `unityear_12_enrolments` were insignificant, suggesting that there were no differences between unit 11 and unit 12 units.

## Interpreting final model

### Composite model
- Level one (measurement variable)
$$Y_{tij} = \pi_{0ij} + \pi_{1ij}year94_{tij} + \epsilon_{tij}$$

- Level two (schools within postcodes) 
  $$\pi_{0ij} = \beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + u_{0ij} \\ 
    \pi_{1ij} = \beta_{10j} + \beta_{11j}unit_{ij} + u_{1ij}$$

- Level three (postcodes)
  $$\beta_{00j} = \gamma_{000} + r_{00j} \\
    \beta_{01j} = \gamma_{010} + r_{01j} \\
    \beta_{02j} = \gamma_{020} + r_{02j} \\
    \beta_{10j} = \gamma_{100} \\
    \beta_{11j} = \gamma_{110}  $$


Therefore, the composite model can be written as:

$$\begin{aligned} Y_{tij} =\ & \pi_{0ij} + \pi_{1ij}year94_{tij} + \epsilon_{tij} \\ =\ & (\beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + u_{0ij}) + (\beta_{10j} + \beta_{11j}unit_{ij} + u_{1ij})year94_{tij} + \epsilon_{tij} \\ =\ & \left[\gamma_{000} + r_{00j} + (\gamma_{010} + r_{01j})sector_{ij} + (\gamma_{020} + r_{02j})unit_{ij} + u_{0ij} \right] + \left[\gamma_{100} + \gamma_{110}unit_{ij} + u_{1ij}\right]year94_{tij} + \epsilon_{tij} \\ =\ & \left[\gamma_{0000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{100}year94_{tij} + \gamma_{110}unit_{ij}year94_{tij} \right] + \left[r_{00j} + r_{01j}sector_{ij} + r_{02j}unit_{ij} + u_{0ij} + u_{1ij}year94_{tij} + \epsilon_{tij} \right]  \end{aligned}$$
### Fixed effects

```{r}
# Extract fixed effects for final model
fixef_f <- fixef(model_f)

# \gamma_{0000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{100}year94_{tij} + 
# \gamma_{110}unit_{ij}year94_{tij}

# Catholic (unit 11)
fit_cat_unit11 <- fixef_f[[1]] + fixef_f[[2]] * c(0:30)

# Catholic (unit 12)
fit_cat_unit12 <-
  fixef_f[[1]] + fixef_f[[5]] + fixef_f[[2]] * c(0:30) + fixef_f[[6]] * c(0:30)

# Government (unit 11)
fit_gov_unit11 <-
  fixef_f[[1]] + fixef_f[[3]] + fixef_f[[2]] * c(0:30)

# Government (unit 12)
fit_gov_unit12 <-
  fixef_f[[1]] + fixef_f[[3]] + fixef_f[[5]] + fixef_f[[2]] * c(0:30) + fixef_f[[6]] * c(0:30)

# Independent (unit 11)
fit_ind_unit11 <-
  fixef_f[[1]] + fixef_f[[4]] + fixef_f[[2]] * c(0:30)

# Independent (unit 12)
fit_ind_unit12 <-
  fixef_f[[1]] + fixef_f[[4]] + fixef_f[[5]] + fixef_f[[2]] * c(0:30) + fixef_f[[6]] * c(0:30)
```

```{r}
fit_f <-
  tibble(
    # Unit 11
    Catholic_unit11 = fit_cat_unit11,
    Government_unit11 = fit_gov_unit11,
    Independent_unit11 = fit_ind_unit11,
    # Unit 12
    Catholic_unit12 = fit_cat_unit12,
    Government_unit12 = fit_gov_unit12,
    Independent_unit12 = fit_ind_unit12,
    # Time variables
    year92 = 0:30,
    completion_year = year92 + 1992
  )

fit_f <- fit_f %>% 
  pivot_longer(cols = Catholic_unit11:Independent_unit12,
               names_to = "sector_unit",
               values_to = "fit") 

fit_f <- fit_f %>% 
  # Separate sector and unit into two variables
  separate(sector_unit, 
           into = c("sector", "unit"), 
           sep = "_",
           remove = FALSE) # Keep old variable for grouping in plot
```

```{r, eval=FALSE, echo=TRUE}
summary(model_f)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model_f)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model_f))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model_f)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model_f)$ngrps[2])
```

Notably, the model assumes that enrolments in different postcodes are assumed to increase at the same rate (as justified by the parametric bootstrap while testing for random effects). Using the model output above (see [step 9](##step-nine) for detailed explanation on fixed effects), the estimated increase in mean enrolments for schools between postcodes are estimated to increase at a rate of 0.9506\% per year. 


```{r agri-sci-fixef, fig.cap = "Fixed effects of the final model for Agricultural Science"}
fit_f %>% 
  ggplot(aes(x = completion_year,
             y = fit,
             group = sector_unit,
             colour = sector)) +
  geom_line(aes(linetype = unit),
            size = 1,
            alpha = 0.7) +
  scale_colour_discrete_qualitative() +
  labs(title = "Fixed effects of final model",
       x = "Completion Year",
       y = "Predicted log enrolments") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 90)) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) 
```

Based on the fixed effects, independent schools are expected to have the highest enrolments over the years. In all sectors, unit 12 have lower initial status (*i.e.* lower enrolments when subject is first introduced), however, they are expected to increase at a much higher rate relative to unit 11 units. Intuitively, this suggests that on average, there may be more students taking this subject in year 10, before re-enrolling again in year 12, or in the more extreme case, students are dropping the subject after completing year 11.

### Random effects

```{r}
# Random effects for schools within postcodes
ranef_school_f <- as_tibble(ranef(model_f)) %>%
  filter(grpvar == "school_postcode:qcaa_school_id") %>% 
  separate(
    col = grp,
    into = c("school_postcode", "qcaa_school_id"),
    sep = ":",
    remove = FALSE
  ) %>% 
  # Rename intercept and slope names
  mutate(term = if_else(term == "(Intercept)",
                        true = "Random Intercept",
                        false = "Random Slope")) 



# Random effects for between postcodes
ranef_district_f <- as_tibble(ranef(model_f)) %>% 
  filter(grpvar == "school_postcode") %>% 
  # Rename intercept and slope names
  mutate(term =  as.character(term),
         term = factor(if_else(
           term == "(Intercept)",
           true = "Random Intercept",
           false = "Random slope"
         ))) %>% 
  rename(school_postcode = grp)
```


```{r}
# Plot random effect for schools nested within postcodes
ranef_school_f %>% 
  group_by(term) %>% 
  # Reorder group based on by conditional means for plotting
  mutate(qcaa_school_id = fct_reorder(qcaa_school_id, condval)) %>% 
  ggplot() +
  geom_point(aes(x = condval,
                 y = qcaa_school_id)) +
  geom_vline(xintercept = 0,
             size = 1,
             colour = "red") +
  facet_wrap(~ term,
             scales = "free_x")
```

A clear negative correlation in the random intercept and slope can be distinguished, indicating that schools with larger enrolments when the subject was first introduced are expected to show a smaller increase (decrease) in enrolments over the years. Based on the model output, the correlation between random intercept and slope was -0.92.

```{r agri-sci-postcode-ranef, fig.cap = "Random intercept for districts"}
# Plot random effects for between postcodes
ranef_district_f %>% 
# Reorder group based on by conditional means
  mutate(school_postcode = fct_reorder(school_postcode, condval)) %>% 
  ggplot() + 
  geom_point(aes(x = condval,
                 y = school_postcode)) +
  geom_vline(xintercept = 0,
             colour = "red",
             size = 1) +
  facet_wrap(~ term,
             scales = "free_x")
```

As there is no random slope, enrolments for the across all postcodes are estimated to be the same (justified by the parametric bootstrap). As shown in Figure \@ref(fig:agri-sci-postcode-ranef), most of the variations are accounted for in the random intercept, which suggests that some postcodes are associated with larger schools (and enrolments) relative to other postcodes. Schools within postcode 4350 (In Toowoomba district) are predicted to have the highest initial status while schools within postcode 4570 (Wide Bay district) are predicted to have the lowest initial status.

### Predictions

```{r agri-sci-pred, fig.cap = "Model predictions for 20 randomly selected schools"}
# Predictions for 20 randomly selected schools for year 11 enrolments
set.seed(2021)

agri_sci_long %>% 
  filter(unit == "year_11_enrolments") %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, 20)) %>% 
  mutate(pred = predict(model_f, newdata = .)) %>% 
  ggplot() +
  geom_line(aes(x = completion_year,
                y = log(enrolments),
                group = qcaa_school_id)) +
  geom_line(aes(x = completion_year,
                y = pred,
                group = qcaa_school_id),
            colour = "orange") +
  facet_wrap(~ qcaa_school_id)
```



