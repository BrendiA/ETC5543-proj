---
title: "Multilevel Model for Physics"
author: "Brendi Ang"
date: "17/10/2021"
output: 
  bookdown::html_document2:
    theme: flatly
    toc: true
    number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(tidyverse)
library(broom)
library(broom.mixed)
library(colorspace)
library(kableExtra)
library(lme4)
library(patchwork)

ggplot2::theme_set(theme_bw())

select <- dplyr::select
```

```{r, include=FALSE, warning=FALSE}
# Read-in data
mathsci_all <- read_csv(here::here("data/mathsci_all.csv"),
                        col_types = cols(doe_centre_code = col_factor()))

# Convert data types
mathsci_all <- mathsci_all %>% 
  mutate(across(.cols = c(qcaa_subject_id, 
                          subject_type,
                          qcaa_school_id,
                          sector,
                          school_postcode
                          ),
                ~ as.factor(.x))) 
``` 


```{r}
phys <- mathsci_all %>% 
  filter(subject_name == "Physics")

phys_long <- phys %>% 
  pivot_longer(cols = year_11_enrolments:year_12_enrolments,
               names_to = "unit",
               values_to = "enrolments") 
```


# Exploring the dataset with basic linear model

```{r phys-eda, fig.cap="Basic linear model for 20 randomly selected schools to provide an at-a-glance visualisation of enrolment trends within schools for Physics"}
# Fit a linear model for 20 random sampled schools
set.seed(190)

phys_long %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, size = 21),
         enrolments > 0) %>% 
  ggplot(aes(x = completion_year,
             y = enrolments)) +
  geom_point() +
  stat_smooth(method = "lm",
              colour = "orange",
              se = FALSE) +
  facet_wrap(~ qcaa_school_id) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) +
  theme(axis.text.x = element_text(angle = 90))
```

Figure \@ref(fig:phys-eda) fits a linear model for enrolments for a random sample of 20 schools. School cohorts vary greatly in sizes; For instance, most schools in these random draws have approximately less than 50 enrolments per cohort except for school 2 and school 11. As each panel have the same y and x-axis, the fitted line are computed relative to one another. It is apparent that school 2 and school 11 have significantly larger increase in enorlments than all the other randomly selected schools. 

## Getting the data ready for modelling

### Removing zero enrolments

All zero enrolments in a given year will be removed for modelling. As aforementioned, most of the zero enrolments in year 11 (refer to Figure \@ref(fig:year-11-enrolments-all)) were attributed to the 2007 prep year cohort while zero enrolments in year 12 relates to the first year in which a school introduces the subject. Other zero enrolments mostly relates to smaller schools with little to no enrolments in the subject for a given year. These zero enrolments will be removed for modelling purposes.

### Linearise response variable using log transformation

```{r phys-log-scale, fig.cap = "Effects of log transformation for response variable (enrolments) in Specialist Mathematics subject"}
p1 <- phys_long %>%
  ggplot(aes(x = enrolments)) +
  geom_histogram(binwidth = 15,
                 fill = "white",
                 colour = "black") +
  geom_density(aes(y = 15 * ..count..),
               fill = "steelblue",
               alpha = 0.4) +
  labs(title = "Before log transformation",
       x = "Enrolments",
       y = "Density")

p2 <- phys_long %>%
  ggplot(aes(log(enrolments))) +
  geom_histogram(binwidth = 0.3,
                 fill = "white",
                 colour = "black") +
  geom_density(aes(y = 0.3 * ..count..),
               fill = "steelblue",
               alpha = 0.4) +
  labs(title = "After log transformation",
       x = "Log Enrolments",
       y = "Density")

p1 / p2
```

As multilevel model assumes normality in the error terms, a log transformation is utilised to allow models to be estimated by the linear mixed models. The log transformation allows enrolment numbers to be approximately normally distributed (Figure \@ref(fig:phys-log-scale).

```{r}
# --- Cleaning script

phys <- phys %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove zero enrolments
  filter(year_12_enrolments != 0,
         year_11_enrolments != 0)

phys_long <- phys_long %>% 
  # Remove graduating cohort 2019 
  filter(completion_year != 2019) %>% 
  # Remove zero enrolments
  filter(enrolments != 0) %>% 
  # Recentre year
  mutate(year92 = completion_year - min(completion_year),
         .before = completion_year) %>% 
  # Log transformation of response variable
  mutate(log_enrolments = log(enrolments))
```

## Unconditional means model

```{r}
# ----- Fit possible null model

# Two-level: Within schools
model0.0 <- lmer(log_enrolments ~ 1 + (1 | qcaa_school_id),
                 data = phys_long)

# Three-level: Schools nested within postcodes
model0.1 <- lmer(log_enrolments ~ 1 + (1 | school_postcode/qcaa_school_id),
                 data = phys_long)

# Three-level Schools nested within districts
model0.2 <- lmer(log_enrolments ~ 1 + (1 | qcaa_district/qcaa_school_id),
                 data = phys_long)
```

```{r phys-init-models}
# Obtain AIC for each null model
model0_AIC <- AIC(model0.0, model0.1, model0.2) 

# Change row names 
rownames(model0_AIC) <- c("Model0.0: Within schools",
                          "Model0.1: Schools nested within postcodes",
                          "Model0.2: Schools nested within districts")

model0_AIC %>% 
  arrange(AIC) %>% 
  kable(caption = "AIC values for all candidate models for Physics") %>% 
  kable_styling(full_width = FALSE,
                bootstrap_options = c("hover", "striped"))
```

As per [Step 3](#step-three), the three potential models are fitted, with the AIC shown in Table \@ref(tab:chem-init-models). Based on the AIC, `model0.2`, corresponding the schools nested within districts is the best model and will be used in the subsequent analysis. 

### Intraclass correlation ($ICC$)

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model0.2)

cat("Random effects:", "\n")

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

cat("\n","Fixed effects:", "\n")
# Extract fixed effects coefficient
coef(summary(model0.2))

# Print grouping structure
cat("\n",
    "Number of schools (level-two group) =",
    summary(model0.2)$ngrps[1], "\n", 
    "Number of district (level-three group) =",
    summary(model0.2)$ngrps[2])
```

This model takes into account 445 schools nested in 13 districts. In a three-level multilevel model, two intraclass correlations can be obtained using the model summary output above:

The **level-two ICC** is the correlation between a school $i$ from a certain district $j$ in time $t$ and in time $t^*$:

$$\text{level-two ICC} = \frac{\tau^{2}_{00}}{\tau^{2}_{00} + \phi^{2}_{00} + \sigma^2} = \frac{0.5294}{(0.5294 + 0.1178 + 0.2188)} = 0.6113$$

The **level-three ICC** refers to the correlation between different schools $i$ and $i^*$ from a specific district $j$. 

$$\text{level-three ICC} = \frac{\phi^2_{00}}{\tau^2_{00} + \phi^2_{00} + \sigma^2} = \frac{0.1178}{(0.5294 + 0.1178 + 0.2188)} = 0.1360$$

## Unconditional growth model

```{r}
# Unconditional growth model
model1.0 <- lmer(log_enrolments ~ year92 + 
                (year92 | qcaa_district:qcaa_school_id) + 
                (year92 | qcaa_district),
                REML = TRUE,
                control = lmerControl(optimizer = "bobyqa"),
                data = phys_long)
```

```{r, echo=TRUE, eval=FALSE}
summary(model)
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model1.0)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model1.0))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model1.0)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model1.0)$ngrps[2])
```

- $\pi_{0ij}$ = 2.3418: Initial enrolments for school $i$ in district $j$ (*i.e.* expected log enrolments when time = 0)
- $\pi_{1ij}$ = 0.01183: Growth rate for student $i$ in school $j$
- $\epsilon_{tij$ = 0.1686: Residual associated with student score at a specific time point 

When the subject was first introduced in 1992, school were expected to have 10.40 ($e^{2.3418}$), on average. Enrolments are expected to increase by 1.19% ($(e^{0.01183} - 1) \times 100$) per year. The estimated within-schools variance decreased by 22.9342\% (0.2188 to 0.16862), implying that 22.9342\% of within-school variability can be explained by the linear growth over time.


## Testing fixed effects

```{r}
# Largest possible model
model4.0 <- lmer(log_enrolments ~ year92*sector*unit +
                (year92 | qcaa_district:qcaa_school_id) + 
                (year92 | qcaa_district),
                REML = FALSE,
                data = phys_long)

# ----- Specify all models with different fixed effects

# --- Remove three-way interaction

model4.1 <- update(model4.0, . ~ . - sector:unit:year92)

# --- Remove two two-way interaction

model4.2 <- update(model4.1, . ~. - sector:year92 - unit:year92)

model4.3 <- update(model4.1, . ~. - unit:sector - sector:year92)

model4.4 <- update(model4.1, . ~. - unit:sector - unit:year92)

# --- Remove one two-way interaction

# Remove sector:unit interaction
model4.5 <- update(model4.1, . ~ . - sector:unit)

# Remove sector:year92 interaction
model4.6 <- update(model4.1, . ~ . - sector:year92)

# Remove unit:year92 interaction
model4.7 <- update(model4.1, . ~ . - unit:year92)

# --- No interactions

# Include 2 fixed effects
model4.8 <- update(model4.1, . ~. - unit:year92 - sector:year92 - unit:year92)

# Remove unit fixed effects
model4.9 <- update(model4.8, . ~. - unit)

# Remove sector fixed effects
model4.10 <- update(model4.8, . ~. - sector)
```


```{r phys-test-fixef}
# ANOVA test
model_anova <- anova(
  model4.0,
  model4.1,
  model4.2,
  model4.3,
  model4.4,
  model4.5,
  model4.6,
  model4.7,
  model4.8,
  model4.9,
  model4.10
)


model_anova %>% 
  as_tibble() %>% 
  select(AIC) %>% 
  mutate(model = rownames(model_anova),
         .before = AIC) %>% 
  arrange(AIC) %>% 
  kable(caption = "AIC for all possible models with different combinations of fixed effects") %>% 
  kable_styling(full_width = FALSE)
```

As highlighted in [step 6](#step-six), `sector` and `unit` will be added as predictors to the model. The largest possible model will be fitted, before removing fixed effects one by one while recording the AIC for each model. In this case, `model4.0` corresponds to the largest possible model while `model4.10` is the smallest possible model. The model with the optimal (lowest) AIC is `model4.7` (Table \@ref(tab:chem-test-fixef)). The next section will test the selected model's random effects to build the final model.

## Parametric bootstrap to test random effects

```{r}
bootstrapAnova <- function(mA, m0, B = 1000){
  oneBootstrap <- function(m0, mA){
    
    # Regenerate new set of response with the null model
    d <- drop(simulate(m0))
    
    # Fit both null and full model to the new data
    m2 <- refit(mA, newresp=d)
    m1 <- refit(m0, newresp=d)
    
    # Return chisq test statistic
    return(anova(m2,m1)$Chisq[2])
  }  
  
  # Conduct test 1,000 times and
  # Store chisq test statistic for each iteration
  nulldist <- replicate(B, oneBootstrap(m0, mA))
  
  # chisq statistic based on the proposed and null model
  ret <- anova(mA, m0)
  
  # Change p-value to bootstrap p-value
  # Proportion of times simulated chisq statistic > actual chisq test statistic
  ret$"Pr(>Chisq)"[2] <- mean(ret$Chisq[2] < nulldist)
  
  # Change name from Pr(>Chisq) to Pr_boot(>Chisq)
  names(ret)[8] <- "Pr_boot(>Chisq)"
  
  # Change heading of model output
  attr(ret, "heading") <- c(attr(ret, "heading")[1], 
    paste("Parametric bootstrap with", B,"samples."),
    attr(ret, "heading")[-1])
  
  attr(ret, "nulldist") <- nulldist
  return(ret)
}
```

```{r}
# Best model based on AIC and BIC

# Proposed model
balt <- lmer(log_enrolments ~ year92 + sector + year92:sector + unit + sector:unit + 
               (year92 | qcaa_district:qcaa_school_id) +  
               (year92 | qcaa_district),
             REML = FALSE,
             data = phys_long)

# Null model
bnull <- lmer(log_enrolments ~ year92 + sector + year92:sector + unit + sector:unit + 
               (year92 | qcaa_district:qcaa_school_id) +  
               (1 | qcaa_district),
              REML = FALSE,
              data = phys_long)

actual <- 2*(logLik(balt) - logLik(bnull))
```

```{r, eval=FALSE, warning=FALSE, message=FALSE}
bootstrapLRT <- bootstrapAnova(mA = balt,
                               m0 = bnull, 
                               B = 1000)

save(bootstrapLRT, file = here::here("data/bootstrapLRT/phys.rda"))
```

```{r phys-bootstrapLRT-tab}
load(here::here("data/bootstrapLRT/phys.rda"))

as_tibble(bootstrapLRT) %>% 
  kable(caption = "Parametric Bootstrap to compare larger and smaller, nested model") %>% 
  kable_styling(full_width = FALSE)
```


```{r phys-bootstrapLRT-plot, fig.cap = "Histogram of likelihood ratio test statistic, with a red vertical line indicating the likelihood ratio test statistic for the actual model"}
nullLRT = attr(bootstrapLRT, "nulldist")
x = seq(0, max(nullLRT), length = 100)
y = dchisq(x, 2)

nullLRT.1 <- as.data.frame(cbind(nullLRT = nullLRT, x = x, y = y))

ggplot(nullLRT.1) +
  geom_histogram(
    aes(x = nullLRT, y = ..density..),
    bins = 25,
    color = "black",
    fill = "grey80"
  ) + 
  geom_vline(xintercept = actual, 
             size = 1,
             colour = "red") +
  geom_line(aes(x = x, y = y)) +
  labs(y = "Density",
       x = "Likelihood Ratio Test Statistics from Null Distribution") 
```

The parametric bootstrap is used to approximate the likelihood ratio test statistic to produce a more accurate p-value by simulating data under the null hypothesis (detailed explanation can be found in [step 7](#step-seven). Figure \@ref(fig:phys-bootstrapLRT-tab) displays the likelihood ratio test statistic from the null distribution, with the red line representing the likelihood ratio test statistic using the actual data. The bootstrap likelihood ratio test is significant at the 1% level ($\chi^2$ = 7.2276, $p$-value = 0.006 -- see Table), suggesting that the larger model (with random slope at level three) is the better alternative.

## Confidence inetrval

```{r}
# Fit best model with restricted maximum likelihood estimates
model_f <- lmer(log_enrolments ~ year92 + sector + year92:sector + unit + sector:unit + 
               (year92 | qcaa_district:qcaa_school_id) +  
               (year92 | qcaa_district),
             REML = TRUE,
             control = lmerControl(optimizer = "bobyqa"),
             data = phys_long)
```

```{r, eval=FALSE}
confint_f <- confint(model_f,
                     method = "boot",
                     oldNames = FALSE)

save(confint_f, file = here::here("data/confint/phys.rda"))
```

```{r phys-confint}
load(here::here("data/confint/phys.rda"))

as_tibble(confint_f) %>% 
  mutate(var = rownames(confint_f),
         .before = `2.5 %`) %>% 
  kable(caption = "95% confidence intervals for fixed and random effects in the final model") %>% 
  kable_styling(full_width = FALSE)
```

The parametric bootstrap is utilised to construct confidence intervals (as detailed in [step 8](#step-eight)). If the confidence intervals for the random effects does not include 0, it provides statistical evidence that the p-value is less than 0.5. In other words, it suggests that the random effects and the correlation between the random effects are significant at the 5% level.  The 95% confidence interval is shown above (Table \@ref(tab:phys-confint)), and the random effects all exclude 0, further reiterating that they are statistically significant at the 5% level.

## Interpreting final model

### Fixed effects

- Level one (measurement variable)
$$Y_{tij} = \pi_{0ij} + \pi_{1ij}year92_{tij} + \epsilon_{tij}$$

- Level two (schools within districts) will contain new predictor(`sector`)
  $$\pi_{0ij} = \beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + \beta_{03j}sector_{ij}unit_{ij} + u_{0ij} \\ 
    \pi_{1ij} = \beta_{10j} + \beta_{11j}sector_{ij} + u_{1ij}$$

- Level three (districts)
  $$\beta_{00j} = \gamma_{000} + r_{00j} \\
    \beta_{01j} = \gamma_{010} + r_{01j} \\
    \beta_{02j} = \gamma_{020} + r_{02j} \\
    \beta_{03j} = \gamma_{030} + r_{03j} \\
    \beta_{10j} = \gamma_{100} + r_{10j} \\
    \beta_{11j} = \gamma_{110} + r_{11j}$$

Therefore, the composite model can be written as

$$\begin{aligned} 
Y_{tij} =\ &\pi_{0ij} + \pi_{1ij}year92_{tij} + \epsilon_{tij} \\

        =\ &(\beta_{00j} + \beta_{01j}sector_{ij} + \beta_{02j}unit_{ij} + \beta_{03j}sector_{ij}unit_{ij} + u_{0ij}) + 
           (\beta_{10j} + \beta_{11j}sector_{ij} + u_{1ij})year92_{tij} + \epsilon_{tij} \\ 
           
        =\ & \left[(\gamma_{000} + r_{00j}) + (\gamma_{010} + r_{01j})sector_{ij} + (\gamma_{020} + r_{02j})unit_{ij} + 
              (\gamma_{030} + r_{03j})sector_{ij}unit_{ij} + u_{0ij} \right] + \\ 
            & \left[(\gamma_{100} + r_{10j}) + (\gamma_{110} + r_{11j})sector_{ij} + u_{1ij} \right]year92_{tij} + \epsilon_{tij} \\
            
        =\ & \left[\gamma_{000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{020}sector_{ij}unit_{ij} +
            \gamma_{100}year92_{tij} + \gamma_{110}year92_{tij}sector_{ij} \right] + \\ 
            & \left[ r_{00j} + r_{01j}sector_{ij} + r_{02j}unit_{ij} + r_{03j}sector_{ij}unit_{ij} + u_{0ij} + r_{10j}year92_{tij} +
            r_{11j}year92_{tij}sector_{ij} + u_{1ij} \epsilon_{tij} \right] 
\end{aligned}$$

```{r}
# Extract fixed effects for final model
fixef_f <- fixef(model_f)

# \gamma_{000} + \gamma_{010}sector_{ij} + \gamma_{020}unit_{ij} + \gamma_{020}sector_{ij}unit_{ij} + 
# \gamma_{100}year92_{tij} + \gamma_{110}year92_{tij}sector_{ij}

# Catholic (unit 11)
fit_cat_unit11 <- fixef_f[[1]] + fixef_f[[2]] * c(0:30)

# Catholic (unit 12)
fit_cat_unit12 <- fixef_f[[1]] + fixef_f[[5]] + fixef_f[[2]] * c(0:30) 
  
# Government (unit 11)
fit_gov_unit11 <- fixef_f[[1]] + fixef_f[[3]] + fixef_f[[2]] * c(0:30) + fixef_f[[6]] * c(0:30)

# Government (unit 12)
fit_gov_unit12 <- fixef_f[[1]] + fixef_f[[3]] + fixef_f[[5]] + fixef_f[[8]] + fixef_f[[2]] * c(0:30) + fixef_f[[6]] * c(0:30)
  
# Independent (unit 11)
fit_ind_unit11 <- fixef_f[[1]] + fixef_f[[4]] + fixef_f[[2]] * c(0:30) + fixef_f[[7]] * c(0:30)
  
# Independent (unit 12)
fit_ind_unit12 <- fixef_f[[1]] + fixef_f[[4]] + fixef_f[[5]] + fixef_f[[9]] + fixef_f[[2]] * c(0:30) + fixef_f[[7]] * c(0:30)
```

```{r}
fit_f <-
  tibble(
    # Unit 11
    Catholic_unit11 = fit_cat_unit11,
    Government_unit11 = fit_gov_unit11,
    Independent_unit11 = fit_ind_unit11,
    # Unit 12
    Catholic_unit12 = fit_cat_unit12,
    Government_unit12 = fit_gov_unit12,
    Independent_unit12 = fit_ind_unit12,
    # Time variables
    year92 = 0:30,
    completion_year = year92 + 1992
  )

fit_f <- fit_f %>% 
  pivot_longer(cols = Catholic_unit11:Independent_unit12,
               names_to = "sector_unit",
               values_to = "fit") 

fit_f <- fit_f %>% 
  # Separate sector and unit into two variables
  separate(sector_unit, 
           into = c("sector", "unit"), 
           sep = "_",
           remove = FALSE) # Keep old variable for grouping in plot
```

```{r}
# --- Model summary output

# Extract variance and correlation component
vc <- VarCorr(model_f)

# Print variance and standard deviation of random effects
print(vc, comp = c("Variance", "Std.Dev."))

# Extract fixed effects coefficient
coef(summary(model_f))

# Print grouping structure
cat(" Number of Level Two groups = ",
    summary(model_f)$ngrps[1], "\n", 
    "Number of Level Three groups = ",
    summary(model_f)$ngrps[2])
```

Using the model output above (see [step 9](##step-nine) for detailed explanation on fixed effects), the estimated increase in mean enrolments for government schools is 0.1082\% ($e^{0.0131073 - 0.0120259} - 1) \times  100$), which is 1.1954\% ($(e^{0.01626900} - 1) \times 100$) less than that of catholic schools. On the other hand, the mean enrolments for independent schools are estimated to increase by 3.2399\% ($(e^{0.0131073 + 0.0187781} - 1) \times  100$) each year, which is 1.8956\% ($(e^{0.0187781} - 1) \times  100$) more than catholic schools.


```{r phys-fixef, fig.cap = "Fixed effects of the final model for Physics"}
fit_f %>% 
  ggplot(aes(x = completion_year,
             y = fit,
             group = sector_unit,
             colour = sector)) +
  geom_line(aes(linetype = unit),
            size = 1,
            alpha = 0.7) +
  scale_colour_discrete_qualitative() +
  labs(title = "Fixed effects of final model",
       x = "Completion Year",
       y = "Predicted log enrolments") +
  theme(legend.position = "bottom",
        legend.direction = "vertical",
        axis.text.x = element_text(angle = 90)) +
  scale_x_continuous(breaks = seq(1992, 2022, by = 2),
                     labels = seq(1992, 2022, by = 2)) 
```

The fixed effects can be visualised in Figure \@ref(fig:phys-fixef). It is manifest that independent schools shows the largest increase in enrolments over the years, while government schools shows a slight decrease in enrolments across the years, on average. Each sector demonstrated that the average year 11 enrolments was less than year 12 enrolments, why may imply that students are not continuing their year 12 syllabus after completing year 11.

### Random effects

```{r}
# Random effects for schools within districts
ranef_school_f <- as_tibble(ranef(model_f)) %>%
  filter(!grp %in% unique(phys$qcaa_district)) %>% 
  separate(
    col = grp,
    into = c("qcaa_district", "qcaa_school_id"),
    sep = ":",
    remove = FALSE
  ) %>% 
  # Rename intercept and slope names
  mutate(term = if_else(term == "(Intercept)",
                        true = "Intercept",
                        false = "Slope")) 

# Random effects for between districts
ranef_district_f <- as_tibble(ranef(model_f)) %>% 
  filter(grp %in% unique(phys$qcaa_district)) %>% 
  group_by(term) %>% 
  rename(qcaa_district = grp) %>% 
  # Rename intercept and slope names
  mutate(term =  as.character(term),
         term = factor(if_else(
           term == "(Intercept)",
           true = "Intercept",
           false = "Slope"
         )))
```

```{r phys-school-ranef, fig.cap = "Random effects for schools"}
# Plot random effect for schools nested within districts
ranef_school_f %>% 
  group_by(term) %>% 
  # Reorder group based on by conditional means for plotting
  mutate(qcaa_school_id = fct_reorder(qcaa_school_id, condval)) %>% 
  ggplot() +
  geom_point(aes(x = condval,
                 y = qcaa_school_id)) +
  geom_vline(xintercept = 0,
             size = 1,
             colour = "red") +
  facet_wrap(~ term,
             scales = "free_x")
```

Figure \@ref(fig:phys-school-ranef) displays the random effects for a given school. It is apparent that the random intercepts and slopes are negatively correlated, where a large intercept is associated with a smaller random slope (correlation = -0.70, as shown in the model output). This indicates that a larger school is associated with a smaller increase (decrease) in enrolments over the years while smaller schools are predicted to have larger increase in enrolments over the years.

```{r phys-district-ranef, fig.cap = "Random intercept for districts"}
# Plot random effects for between districts
ranef_district_f %>% 
# Reorder group based on by conditional means
  mutate(qcaa_district = fct_reorder(qcaa_district, condval)) %>% 
  ggplot() + 
  geom_point(aes(x = condval,
                 y = qcaa_district)) +
  geom_vline(xintercept = 0,
             colour = "red",
             size = 1) +
  facet_wrap(~ term,
             scales = "free_x")
```

The model includes a random slope at level three, and the effects of the random intercept and slope in level three is shown in Figure \@ref(fig:phys-district-ranef). As shown in the model output, correlation between the random intercept and slope is 0.62. Loosely speaking, this suggests that districts with large enrolments are going to be larger, while smaller districts are going to increase (decrease) at a slower rate. Based on Figure \@ref(fig:phys-district-ranef), Gold Coast are estimated to have the highest slope, indicating that the rate of change in enrolment is the greatest compared to the other districts.

### Predictions

```{r phys-pred, fig.cap = "Model predictions for 20 randomly selected schools"}
# Predictions for 20 randomly selected schools for year 11 enrolments
set.seed(1995)
phys_long %>% 
  filter(unit == "year_11_enrolments") %>% 
  filter(qcaa_school_id %in% sample(qcaa_school_id, 20)) %>% 
  mutate(pred = predict(model_f, newdata = .)) %>% 
  ggplot() +
  geom_line(aes(x = completion_year,
                y = log(enrolments),
                group = qcaa_school_id)) +
  geom_line(aes(x = completion_year,
                y = pred,
                group = qcaa_school_id),
            colour = "orange") +
  facet_wrap(~ qcaa_school_id)
```

Figure \@ref(fig:phys-pred) above shows the predictions for 20 randomly selected schools.

